<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://chriswsq.github.io</id>
    <title>chris&apos;wang</title>
    <updated>2020-11-23T06:07:56.632Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://chriswsq.github.io"/>
    <link rel="self" href="https://chriswsq.github.io/atom.xml"/>
    <subtitle>当你觉得无所事事时，那你就是在虚度光阴</subtitle>
    <logo>https://chriswsq.github.io/images/avatar.png</logo>
    <icon>https://chriswsq.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, chris&apos;wang</rights>
    <entry>
        <title type="html"><![CDATA[neo服务更新]]></title>
        <id>https://chriswsq.github.io/post/neo-fu-wu-geng-xin/</id>
        <link href="https://chriswsq.github.io/post/neo-fu-wu-geng-xin/">
        </link>
        <updated>2020-11-23T06:03:14.000Z</updated>
        <content type="html"><![CDATA[<h1 id="neo服务更新">neo服务更新</h1>
<h2 id="清理旧数据">清理旧数据</h2>
<pre><code class="language-bash">docker rm -f    neo-cli

docker rmi neongd/neo-cli

find  /bsn/neo/ -type d | xargs rm -rf {} \;
</code></pre>
<h2 id="安装新版本neo">安装新版本neo</h2>
<pre><code class="language-bash">docker pull neongd/neo-cli

docker run --name=neo-cli -dit -p 10332-10334:10332-10334  -v /bsn/neo/chain.acc.zip:/neo-cli/chain.acc.zip -v /bsn/neo/ApplicationLogs_00746E41:/neo-cli/ApplicationLogs_00746E41 -v /bsn/neo/Chain_00746E41:/neo-cli/Chain_00746E41 -v /bsn/neo/Index_00746E41:/neo-cli/Index_00746E41 -v /bsn/neo/Nep5BalanceData:/neo-cli/Nep5BalanceData -v /bsn/neo/SystemAssetBalanceData:/neo-cli/SystemAssetBalanceData --restart=always neongd/neo-cli


docker exec -it neo-cli bash

screen -r node

install SimplePolicy
install RpcSecurity
install ApplicationLogs
install ImportBlocks
install RpcWallet
install RpcNep5Tracker
install RpcSystemAsseTtracker
install CoreMetrics
install StatesDumper


docker container restart neo-cli
</code></pre>
<h2 id="查看状态">查看状态</h2>
<p>两个值在变动则为正常</p>
<pre><code class="language-bash">docker exec -it node-cli  bash

screen -r node 

shwo state
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[公链之oasis]]></title>
        <id>https://chriswsq.github.io/post/gong-lian-zhi-oasis/</id>
        <link href="https://chriswsq.github.io/post/gong-lian-zhi-oasis/">
        </link>
        <updated>2020-11-03T08:58:03.000Z</updated>
        <content type="html"><![CDATA[<h2 id="非验证节点">非验证节点</h2>
<p>填写绿洲P2P地址，同步公链数据</p>
<p>（普通节点）</p>
<h2 id="验证节点">验证节点</h2>
<p>需要创建实体，控制网络上的个人或组织的奖金</p>
<p>需要下载oasis app ，生成账户的公私钥</p>
<p>（共识节点）</p>
<h2 id="paratime节点">ParaTime节点</h2>
<p>目前还是测试版本</p>
<ol>
<li>
<p>要运行ParaTime节点，您必须已经是具有在网络上注册的实体ID的Oasis验证器。您可能已经在运行：</p>
<ul>
<li>
<p>一个或多个验证器节点</p>
<p>也就是需要至少有一个共识节点</p>
</li>
<li>
<p>可选的非验证者节点</p>
</li>
</ul>
</li>
</ol>
<h2 id="非验证节点-2">非验证节点</h2>
<p>根据实际需求我们需要使用非验证节点，但非验证节点启动时没有rpc端口，所以要借助网关来代理出去端<br>
口，</p>
<p>参考<br>
https://docs.oasis.dev/general/run-a-node/set-up-your-node/run-non-validator<br>
https://docs.oasis.dev/oasis-core/high-level-components/oasis-node/rpc<br>
https://docs.oasis.dev/general/oasis-network/network-parameters<br>
https://github.com/oasisprotocol/oasis-core/releases/tag/v20.10<br>
https://github.com/oasisprotocol/oasis-core-rosetta-gateway</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis]]></title>
        <id>https://chriswsq.github.io/post/redis/</id>
        <link href="https://chriswsq.github.io/post/redis/">
        </link>
        <updated>2020-10-31T09:29:16.000Z</updated>
        <content type="html"><![CDATA[<p>https://segmentfault.com/a/1190000022808576</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[cita链管理服务部署]]></title>
        <id>https://chriswsq.github.io/post/cita-lian-guan-li-fu-wu-bu-shu/</id>
        <link href="https://chriswsq.github.io/post/cita-lian-guan-li-fu-wu-bu-shu/">
        </link>
        <updated>2020-10-29T08:32:53.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1链管理服务依赖环境">1.链管理服务依赖环境</h2>
<p>•	python &gt;= 3.7.9<br>
•	docker &gt;= 19.0</p>
<ol>
<li>安装3.7.9版本参考：<br>
https://blog.csdn.net/lkgCSDN/article/details/84403329<br>
https://chriswsq.github.io/post/elk-gao-jing-zhi-elastalert-bu-shu-ji-pei-zhi/</li>
</ol>
<p>ln -s  /usr/local/python3/bin/pip3  /usr/bin/pip3<br>
ln -s  /usr/local/python3  /usr/bin/python3<br>
ln -s /usr/local/python3/bin/gunicorn /usr/bin/gunicorn</p>
<h2 id="2链管理服务部署步骤">2.链管理服务部署步骤</h2>
<ul>
<li>解压源码包并进入目录</li>
</ul>
<pre><code class="language-bash">tar xzvf bsn-cita-chain-manager.tar.gz
cd bsn-cita-chain-manager
</code></pre>
<ul>
<li>
<p>安装依赖包<br>
<code>pip3 install -r requirements.txt -i https://pypi.douban.com/simple</code></p>
</li>
<li>
<p>生成pub_key、pri_key</p>
</li>
</ul>
<p>通过cita-cli工具，执行 ./cita-cli key create --algorithm sm2，将 address 字段写入pub_key，将 private 字段写入pri_key</p>
<ul>
<li>修改配置文件</li>
</ul>
<pre><code class="language-bash">vim conf/config.py

# 链节点密钥对的路径及文件名称
PUBKEY_PATH = '/opt/pub_key'
PRIKEY_PATH = '/opt/pri_key'

# cita 镜像名称，rebirth 镜像名称以及 rebirth 依赖 mysql 的镜像名称（下文详细说明）
CITA_IMAGE_VERSION = 'cita/cita-ee:1.3.1-sm2-sm3'
MYSQL_IMAGE_VERSION = 'cita-for-bsn-mysql:5.7'
REBIRTH_IMAGE_VERSION = 'cita-for-bsn-rebirth:0.1'

# 链管理服务产生链配置的目录
CHAIN_CONFIG_PATH = '/opt/all-chain-config'

# 链节点 TLS 证书所在目录
TLS_PATH = '/opt'

# solc 编译器镜像名称
SOLC_IMAGE_VERSION = 'ethereum/solc:0.4.24'
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker-compsoe部署kafka集群]]></title>
        <id>https://chriswsq.github.io/post/docker-compsoe-bu-shu-kafka-ji-qun/</id>
        <link href="https://chriswsq.github.io/post/docker-compsoe-bu-shu-kafka-ji-qun/">
        </link>
        <updated>2020-10-16T10:00:49.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>kafka依赖于zookeeper存放元数据, 所以在创建kafka集群之前需要创建zookeeper; 更多关于zookeeper集群创建见: 使用Docker部署zookeeper集群</p>
<h2 id="拉取镜像">拉取镜像</h2>
<pre><code class="language-bash">docker pull zookeeper:3.4
docker pull zookeeper:3.4 docker pull wurstmeister/kafka_2.13-2.6.0
</code></pre>
<blockquote>
<p>其中kafka版本中的2.12为Scala版本</p>
</blockquote>
<h2 id="创建子网段">创建子网段</h2>
<pre><code class="language-bash">docker network create --subnet 172.30.1.0/16 --gateway 172.30.0.1 kafka
</code></pre>
<pre><code class="language-yaml">version: '3'

services: 
    zoo1:
        image: zookeeper:3.4
        restart: always
        hostname: zoo1
        container_name: zoo1
        ports:
            - 2184:2181
        volumes: 
            - /home/zk/workspace/volumes/zkcluster/zoo1/data:/data
            - /home/zk/workspace/volumes/zkcluster/zoo1/datalog:/datalog
        environment: 
            ZOO_MY_ID: 1
            ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888
        networks:
            kafka:
                ipv4_address: 172.30.0.11

    zoo2:
        image: zookeeper:3.4
        restart: always
        hostname: zoo2
        container_name: zoo2
        ports:
            - 2185:2181
        volumes: 
            - /home/zk/workspace/volumes/zkcluster/zoo2/data:/data
            - /home/zk/workspace/volumes/zkcluster/zoo2/datalog:/datalog
        environment: 
            ZOO_MY_ID: 2
            ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888
        networks:
            kafka:
                ipv4_address: 172.30.0.12

    zoo3:
        image: zookeeper:3.4
        restart: always
        hostname: zoo3
        container_name: zoo3
        ports:
            - 2186:2181
        volumes: 
            - /home/zk/workspace/volumes/zkcluster/zoo3/data:/data
            - /home/zk/workspace/volumes/zkcluster/zoo3/datalog:/datalog
        environment: 
            ZOO_MY_ID: 3
            ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888
        networks:
            kafka:
                ipv4_address: 172.30.0.13

    kafka1:
        image: wurstmeister/kafka
        restart: always
        hostname: kafka1
        container_name: kafka1
        privileged: true
        ports:
            - 9092:9092
        environment:
              KAFKA_ADVERTISED_HOST_NAME: kafka1
              KAFKA_LISTENERS: PLAINTEXT://kafka1:9092
              KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
              KAFKA_ADVERTISED_PORT: 9092
              KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181
        volumes:
            - /home/zk/workspace/volumes/kafkaCluster/kafka1/logs:/kafka
        networks:
            kafka:
                ipv4_address: 172.30.1.11
        extra_hosts: 
            - zoo1:172.30.0.11
            - zoo2:172.30.0.12
            - zoo3:172.30.0.13
        depends_on: 
            - zoo1
            - zoo2
            - zoo3
        external_links: 
            - zoo1
            - zoo2
            - zoo3

    kafka2:
        image: wurstmeister/kafka
        restart: always
        hostname: kafka2
        container_name: kafka2
        privileged: true
        ports:
            - 9093:9093
        environment:
              KAFKA_ADVERTISED_HOST_NAME: kafka2
              KAFKA_LISTENERS: PLAINTEXT://kafka2:9093
              KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093
              KAFKA_ADVERTISED_PORT: 9093
              KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181
        volumes:
            - /home/zk/workspace/volumes/kafkaCluster/kafka2/logs:/kafka
        networks:
            kafka:
                ipv4_address: 172.30.1.12
        extra_hosts: 
            - zoo1:172.30.0.11
            - zoo2:172.30.0.12
            - zoo3:172.30.0.13                
        depends_on: 
            - zoo1
            - zoo2
            - zoo3                
        external_links: 
            - zoo1
            - zoo2
            - zoo3           

    kafka3:
        image: wurstmeister/kafka
        restart: always
        hostname: kafka3
        container_name: kafka3
        privileged: true
        ports:
            - 9094:9094
        environment:
              KAFKA_ADVERTISED_HOST_NAME: kafka3
              KAFKA_LISTENERS: PLAINTEXT://kafka3:9094
              KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9094
              KAFKA_ADVERTISED_PORT: 9094
              KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181
        volumes:
            - /home/zk/workspace/volumes/kafkaCluster/kafka3/logs:/kafka
        networks:
            kafka:
                ipv4_address: 172.30.1.13
        extra_hosts: 
            - zoo1:172.30.0.11
            - zoo2:172.30.0.12
            - zoo3:172.30.0.13                
        depends_on: 
            - zoo1
            - zoo2
            - zoo3                
        external_links: 
            - zoo1
            - zoo2
            - zoo3

networks: 
  kafka:
     ipam:
       config:
         - subnet: 172.30.0.0/16
</code></pre>
<blockquote>
<p>在kafka服务中声明了depends_on, 所以在所有zookeeper启动之后才会真正启动kafka容器</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Loki配置邮件告警]]></title>
        <id>https://chriswsq.github.io/post/loki-pei-zhi-you-jian-gao-jing/</id>
        <link href="https://chriswsq.github.io/post/loki-pei-zhi-you-jian-gao-jing/">
        </link>
        <updated>2020-10-12T09:43:07.000Z</updated>
        <summary type="html"><![CDATA[<p>监控的目的就是及时发现问题去解决处理，那么在告警就是必不可少的。</p>
]]></summary>
        <content type="html"><![CDATA[<p>监控的目的就是及时发现问题去解决处理，那么在告警就是必不可少的。</p>
<!-- more -->
<p>本次告警配置是loki结合grafana来进行邮件告警</p>
<h2 id="grafana配置告警">grafana配置告警</h2>
<p>1.通过标签定位到需要查看的服务,并通过关键字过滤出想要查看的日志内容<br>
<img src="https://chriswsq.github.io/post-images/1602669342426.png" alt="" loading="lazy"></p>
<p>为尽快得到告警邮件这里我们设置带有info字符的日志</p>
<p>2.看下过去一段时间内，日志中带有info字段的趋势<br>
<img src="https://chriswsq.github.io/post-images/1602496164171.png" alt="" loading="lazy"></p>
<p>这里可以看到，日志在不停的打印带有info字段的日志</p>
<p>在数据源中添加一个Prometheus类型，并在地址栏中填写上http://loki:3100/loki ,这样我们就能通过像查询prometheus一样查询日志的走势<br>
<img src="https://chriswsq.github.io/post-images/1602496373242.png" alt="" loading="lazy"></p>
<p>这时候再创建一个pannel来查询info日志的趋势就可以得到如下结果：</p>
<figure data-type="image" tabindex="1"><img src="https://chriswsq.github.io/post-images/1602496436562.png" alt="" loading="lazy"></figure>
<p>接下来的工作，就是在Grafana上添加一个Alert小铃铛，让它每分钟去Loki里面查询有没有出现info字段的日志出现，如果计算出来的结果大于0，就让Grafana通过邮件告警出来。</p>
<figure data-type="image" tabindex="2"><img src="https://chriswsq.github.io/post-images/1602496637970.png" alt="" loading="lazy"></figure>
<p>配置完成后不急保存，我们先Test rule看看rule是否能生效。</p>
<p><img src="https://chriswsq.github.io/post-images/1602496687577.png" alt="" loading="lazy"><br>
看到state:&quot;alerting&quot; 说明现在已经开始报警了</p>
<h2 id="grafana配置邮件">grafana配置邮件</h2>
<pre><code class="language-ini">[smtp]
enabled = true
host = smtp.163.com:25
user = 你的邮箱
# If the password contains # or ; you have to wrap it with triple quotes. Ex &quot;&quot;&quot;#password;&quot;&quot;&quot;
password = 你的密码
;cert_file =
;key_file =
;skip_verify = false
from_address = 你的邮箱
from_name = Grafana
</code></pre>
<p>修改后，保存退出，重启grafana服务</p>
<ul>
<li>登入grafana页面</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://chriswsq.github.io/post-images/1602496941499.png" alt="" loading="lazy"></figure>
<ul>
<li>创建邮件发送规则</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://chriswsq.github.io/post-images/1602497009120.png" alt="" loading="lazy"></figure>
<p>可以为不同的业务组创建不同的通知通道，例如，运维通道为Ops，研发为Dev。然后可以为一个Metrics指定多个通知通道。</p>
<p>Name为通道名称</p>
<p>Type为通道类型，此处选Email，也可选择钉钉告警或者Alert Manager等告警类型。</p>
<p>Default(send on all alerts)开启后，表示在所有Graph Panel中配置告警规则时默认都会选用此通道。该选项默认为关闭。</p>
<p>Include image开启后，表示是发送告警图片。</p>
<p>Disable Resove Message开启后，表示发送恢复邮件，默认关闭。</p>
<p>Send reminders开启后，还需设置下方的发送间隔，表示发送告警邮件的间隔，默认关闭表示若某个告警发生后即使持续很长时间也仅发送一次邮件。</p>
<p>多个邮箱地址间用分号&quot;;&quot;隔开。例：xxx@163.com;xxx@qq.com</p>
<p>创建成功后，点击Send Test 按钮，测试邮件是否能发送成功。（如果发送不成功，可在grafana.log中查看日志信息）</p>
<ul>
<li>在告警中添加配置的告警邮件联系人组</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://chriswsq.github.io/post-images/1602497296964.png" alt="" loading="lazy"></figure>
<ul>
<li>收到告警邮件</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://chriswsq.github.io/post-images/1602497366975.png" alt="" loading="lazy"></figure>
<p>也可以发送图片 ,根据提示安装插件即可<br>
<img src="https://chriswsq.github.io/post-images/1602497453813.png" alt="" loading="lazy"></p>
<p>安装图片插件 官方建议单独新建一个容器去取加载插件而非直接在grafana容器中安装插件</p>
<pre><code class="language-yaml">version: '2'

services:
  grafana:
    image: grafana/grafana:7.0.0-beta1
    ports:
      - 3000
    environment:
      GF_RENDERING_SERVER_URL: http://renderer:8081/render
      GF_RENDERING_CALLBACK_URL: http://grafana:3000/
      GF_LOG_FILTERS: rendering:debug
  renderer:
    image: grafana/grafana-image-renderer:2.0.0-beta1
    ports:
      - 8081
    environment:
      ENABLE_METRICS: 'true'
</code></pre>
<p>结果为<br>
<img src="https://chriswsq.github.io/post-images/1602668961665.png" alt="" loading="lazy"></p>
<p>参考文档：<br>
https://grafana.com/blog/2020/05/07/grafana-7.0-preview-new-image-renderer-plugin-to-replace-phantomjs/<br>
https://www.jianshu.com/p/0982a8ee204c</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[轻量级日志系统Loki原理简介和使用]]></title>
        <id>https://chriswsq.github.io/post/qing-liang-ji-ri-zhi-xi-tong-loki-yuan-li-jian-jie-he-shi-yong/</id>
        <link href="https://chriswsq.github.io/post/qing-liang-ji-ri-zhi-xi-tong-loki-yuan-li-jian-jie-he-shi-yong/">
        </link>
        <updated>2020-10-12T05:40:24.000Z</updated>
        <content type="html"><![CDATA[<pre><code> 目前公司未采用传统的zabbix对服务器监控，而采用了prometheus。以前监控日志的时候是采用
</code></pre>
<p>elastalert+logstash+kibana+filebeat+zookeeper+kafka 来做日志方面的监控告警。后来了解到有loki这样一个日志系统，上网搜了一番资料做了一些对比</p>
<h2 id="日志监控系统elkloki">日志监控系统elk，loki</h2>
<h3 id="elk">ELK</h3>
<p>优势：<br>
1、功能丰富，允许复杂的操作（增减字段，调整字段书序，数据json化）<br>
劣势：<br>
1、主流的ELK（全文检索）或者EFK比较重<br>
2、ES复杂的搜索功能很多都用不上 规模复杂，资源占用高，操作苦难<br>
大多数查询只关注一定时间范围和一些简单的参数（如host、service等）<br>
3、Kibana和Grafana之间切换，影响用户体验<br>
4、倒排索引的切分和共享的成本较高</p>
<h3 id="loki">Loki</h3>
<p>1、最小化度量和日志的切换成本<br>
有助于减少异常事件的响应时间和提高用户的体验<br>
2、在查询语言的易操作性和复杂性之间可以达到一个权衡<br>
3、更具成本效益</p>
<h2 id="项目主页">项目主页</h2>
<p>https://github.com/grafana/loki</p>
<h2 id="loki组件介绍">loki组件介绍</h2>
<h3 id="promtail">Promtail</h3>
<p>用来将容器日志发送到 Loki 或者 Grafana 服务上的日志收集工具<br>
该工具主要包括发现采集目标以及给日志流添加上 Label 标签 然后发送给 Loki<br>
Promtail 的服务发现是基于 Prometheus 的服务发现机制实现的</p>
<h3 id="loki-2">Loki</h3>
<p>受 Prometheus 启发的可以水平扩展、高可用以及支持多租户的日志聚合系统<br>
使用了和 Prometheus 相同的服务发现机制，将标签添加到日志流中而不是构建全文索引<br>
从 Promtail 接收到的日志和应用的 metrics 指标就具有相同的标签集<br>
不仅提供了更好的日志和指标之间的上下文切换，还避免了对日志进行全文索引</p>
<h3 id="grafana">Grafana</h3>
<p>一个用于监控和可视化观测的开源平台<br>
支持非常丰富的数据源<br>
在 Loki 技术栈中它专门用来展示来自 Prometheus 和 Loki 等数据源的时间序列数据<br>
可进行查询、可视化、报警等操作<br>
可以用于创建、探索和共享数据 Dashboard<br>
鼓励数据驱动</p>
<h2 id="安装loki">安装loki</h2>
<p>这里我使用docker 安装，下面是compose文件</p>
<pre><code class="language-yaml">version: &quot;3&quot;
services:
  loki:
    image: &quot;grafana/loki:1.5.0&quot;
    container_name: &quot;loki&quot;
    restart: &quot;always&quot;
    volumes:
      - &quot;/etc/localtime:/etc/localtime&quot;
      - &quot;/usr/local/src/loki/:/etc/loki&quot;
      - &quot;./loki:/loki&quot;
    ports:
      - &quot;3100:3100&quot;
    command: &quot;-config.file=/etc/loki/local-config.yaml&quot;
</code></pre>
<p>记得要修改loki文件夹的所有者为 10001 不然会提示权限不足</p>
<p><code>chown -Rf 10001:10001 loki</code></p>
<p>之后使用docker-compose启动</p>
<p><code>docker-compose up -d</code></p>
<p>就这样loki的服务端就ok了，下面说下几个坑，第一个是</p>
<pre><code class="language-bash">^[level=warn ts=2020-07-06T06:54:12.754273854Z caller=client.go:242 component=client host=192.179.11.1:3100 msg=&quot;error sending batch, will retry&quot; status=429 error=&quot;server returned HTTP status 429 Too Many Requests (429): Ingestion rate limit exceeded (limit: 6291456 bytes/sec) while attempting to ingest '221' lines totaling '101946' bytes, reduce log volume or contact your Loki administrator to see if the limit can be increased&quot;
</code></pre>
<p>当你搭建完成promtail，并且启动发送日志到loki的时候很有可能会碰到这个错误，因为你要收集的日志太多了，超过了loki的限制，所以会报429，如果你要增加限制可以修改loki的配置文件,在limits_config中添加</p>
<p><code>ingestion_rate_mb: 15</code></p>
<p>如果你是老版本的loki，那么是添加</p>
<p><code>ingestion_rate: 25000</code></p>
<p>详细可以看下面</p>
<p>https://github.com/grafana/loki/pull/1278/files/f468d5d258a42316036290fad1b795c40bec22e4#diff-935fd110763ed3367d3ea740a3d3c072</p>
<p>还有一个坑是<br>
<code>level=error ts=2020-07-06T03:58:02.217480067Z caller=client.go:247 component=client host=192.179.11.1:3100 msg=&quot;final error sending batch&quot; status=400 error=&quot;server returned HTTP status 400 Bad Request (400): entry for stream '{app=\&quot;app_error\&quot;, filename=\&quot;/error.log\&quot;, host=\&quot;192.179.11.12\&quot;}' has timestamp too new: 2020-07-06 03:58:01.175699907 +0000 UTC&quot;</code><br>
这个是两台机器的时间相差太大了，我promtail这台机器的时间没有和ntp服务器同步时间，所以就报了这个错误，只要把时间都同步了就好了</p>
<p><strong>我的最终配置文件</strong></p>
<pre><code class="language-yaml">auth_enabled: false

server:
  http_listen_port: 3100

ingester:
  lifecycler:
    address: 127.0.0.1
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
    final_sleep: 0s
  chunk_idle_period: 5m
  chunk_retain_period: 30s

schema_config:
  configs:
    - from: 2020-10-12
      store: boltdb
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 168h

storage_config:
  boltdb:
    directory: /loki/index

  filesystem:
    directory: /loki/chunks

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h
  ingestion_rate_mb: 15

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: true
  retention_period: 336h
</code></pre>
<h2 id="安装promtail">安装promtail</h2>
<p>这里我使用docker 安装，下面是compose文件</p>
<pre><code class="language-yaml">version: &quot;3&quot;
services:
  promtail:
    image: grafana/promtail:1.5.0
    container_name: promtail
    restart: always
    volumes:
      - $PWD:/etc/promtail
      - /bsn/xuperchain/output/logs/xchain.log:/bsn/xuperchain/output/logs/xchain.log
    command:
      -config.file=/etc/promtail/promtail-docker-config.yaml
</code></pre>
<p><strong>配置文件如下</strong></p>
<pre><code class="language-yaml">server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: ./positions.yaml

clients:
  - url: http://192.168.40.6:3100/loki/api/v1/push

scrape_configs:
 - job_name: xuperchain
   static_configs:
   - labels:
      app: local_xchain
      host: 192.168.40.7
      env: prod
      __path__: /bsn/xuperchain/output/logs/xchain.log
</code></pre>
<p>之后使用docker-compose启动</p>
<p><code>docker-compose up -d</code></p>
<h2 id="安装grafana">安装grafana</h2>
<pre><code class="language-yaml">version: &quot;3&quot;
services:
  grafana:
    image: grafana/grafana:7.1.5
    container_name: grafana
    restart: always
    volumes:
     - /bsn/prometheus/grafana:/var/lib/grafana
     - /bsn/prometheus/grafana/grafana.ini:/etc/grafana/grafana.ini
     - /etc/localtime:/etc/localtime
    ports:
     - 3000:3000
</code></pre>
<p><strong>配置文件</strong><br>
下载一个grafana的tar包用即可，也可下载镜像后拷出来grafana.ini文件即可</p>
<p><strong>访问grafana界面</strong></p>
<p>http://192.168.40.6:3000/</p>
<figure data-type="image" tabindex="1"><img src="https://chriswsq.github.io/post-images/1602485759409.png" alt="" loading="lazy"></figure>
<p>默认的登陆账号 admin/admin</p>
<p>然后添加loki数据源<br>
<img src="https://chriswsq.github.io/post-images/1602485889822.png" alt="" loading="lazy"></p>
<p>url添加  http://192.168.40.6:3100<br>
<img src="https://chriswsq.github.io/post-images/1602485944668.png" alt="" loading="lazy"></p>
<p>点击Exporter 选择loki选择相应的label</p>
<figure data-type="image" tabindex="2"><img src="https://chriswsq.github.io/post-images/1602486257770.png" alt="" loading="lazy"></figure>
<h2 id="loki-日志查询语言">Loki 日志查询语言</h2>
<p>基本的LogQL查询由两部分组成：log stream selector、filter expression</p>
<h3 id="log-stream-selector">Log stream selector</h3>
<p>它由一个或多个键值对组成，每个键是一个日志标签，值的话是标签的值，例如<br>
<code>{app=&quot;local_xchain&quot;,host=&quot;192.168.40.7&quot;}</code></p>
<p>在这个例子中，记录具有的标签流app，其值是local_xhcain和的一个标签host，它的值192.168.40.7将被包括在查询结果。注意，这将匹配其标签至少 包含192.168.40.7其名称标签的任何日志流；如果有多个包含该标签的流，则所有匹配流的日志将显示在结果中。</p>
<p>支持以下标签匹配运算符：</p>
<p>=：完全相等。<br>
!=：不相等。<br>
=~：正则表达式匹配。<br>
!~：正则表达式不匹配。</p>
<p>适用于Prometheus标签选择器的相同规则也适用 于Loki日志流选择器。</p>
<p>Filter expression<br>
写入日志流选择器后，可以使用搜索表达式进一步过滤生成的日志集。搜索表达式可以只是文本或正则表达式：</p>
<ul>
<li>{job=“mysql”} |= “error”</li>
<li>{name=“kafka”} |~ “tsdb-ops.*io:2003”</li>
<li>{instance=~“kafka-[23]”,name=“kafka”} != kafka.server:type=ReplicaManager</li>
</ul>
<p>运算符说明</p>
<ul>
<li>|=：日志行包含字符串。</li>
<li>!=：日志行不包含字符串。</li>
<li>|~：日志行匹配正则表达式。</li>
<li>!~：日志行与正则表达式不匹配。</li>
</ul>
<h3 id="指标查询">指标查询</h3>
<h4 id="范围向量">范围向量</h4>
<p>LogQL 与Prometheus 具有相同的范围向量概念，不同之处在于所选的样本范围包括每个日志条目的值1。可以在所选范围内应用聚合，以将其转换为实例向量。</p>
<p><strong>注：对于此种查询，需要添加数据源，选择promethes，但是地址为loki的地址，并在最后添加/lok即可</strong></p>
<p>当前支持的操作功能为：</p>
<ul>
<li>rate：计算每秒的条目数</li>
<li>count_over_time：计算给定范围内每个日志流的条目。</li>
</ul>
<p>//对fluent-bit作业在最近五分钟内的所有日志行进行计数。</p>
<p><code>count_over_time({job=&quot;fluent-bit&quot;}[5m])</code></p>
<p>获取fluent-bit作业在过去十秒内所有非超时错误的每秒速率。</p>
<p><code>rate({job=&quot;fluent-bit&quot;} |= &quot;error&quot; != &quot;timeout&quot; [10s]</code></p>
<h4 id="集合运算符">集合运算符</h4>
<p>与PromQL一样，LogQL支持内置聚合运算符的一个子集，可用于聚合单个向量的元素，从而产生具有更少元素但具有集合值的新向量：</p>
<ul>
<li>sum：计算标签上的总和</li>
<li>min：选择最少的标签</li>
<li>max：选择标签上方的最大值</li>
<li>avg：计算标签上的平均值</li>
<li>stddev：计算标签上的总体标准差</li>
<li>stdvar：计算标签上的总体标准方差</li>
<li>count：计算向量中元素的数量</li>
<li>bottomk：通过样本值选择最小的k个元素</li>
<li>topk：通过样本值选择最大的k个元素</li>
</ul>
<p>可以通过包含a without或 by子句，使用聚合运算符聚合所有标签值或一组不同的标签值：</p>
<p><code>&lt;aggr-op&gt;([parameter,] &lt;vector expression&gt;) [without|by (&lt;label list&gt;)]</code></p>
<p>举例：</p>
<p>统计最高日志吞吐量按container排序前十的应用程序<br>
<code>topk(10,sum(rate({job=&quot;fluent-bit&quot;}[5m])) by(container))</code></p>
<p>获取最近五分钟内的日志计数，按级别分组<br>
<code>sum(count_over_time({job=&quot;fluent-bit&quot;}[5m])) by (level)</code></p>
<p>更多内容请参考：https://github.com/grafana/loki/blob/master/docs/logql.md</p>
<p>参考文档：<br>
https://blog.csdn.net/weixin_44267608/article/details/105264432<br>
https://segmentfault.com/a/1190000023379491<br>
https://www.bboy.app/2020/07/08/%E4%BD%BF%E7%94%A8loki%E8%BF%9B%E8%A1%8C%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[xuperchian  建链未成功手动修复]]></title>
        <id>https://chriswsq.github.io/post/xuperchian change Common node/</id>
        <link href="https://chriswsq.github.io/post/xuperchian change Common node/">
        </link>
        <updated>2020-09-18T03:04:41.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<p>从idc服务器日志中找到 链名的日志  会有创建该链的json文件</p>
<p>#手动修复</p>
<pre><code>#step 1. 创建群组
./xchain-cli wasm invoke group_chain --method addChain -a '{&quot;bcname&quot;:&quot;CounterChain1&quot;}'

#step 2. 添加节点
./xchain-cli wasm invoke group_chain --method addNode -a '{&quot;bcname&quot;:&quot;CounterChain1&quot;, &quot;ip&quot;:&quot;/ip4/127.0.0.1/tcp/47101/p2p/QmVxeNubpg1ZQjQT8W5yZC9fD7ZB1ViArwvyGUB53sqf8e&quot;, 

#step 3. 创建平行链
./xchain-cli transfer --to CounterChain1 --amount 100 --desc createCounterChain1.json


</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[xuperchian 增减共识节点、添加群组操作步骤]]></title>
        <id>https://chriswsq.github.io/post/xuperchian-change-Common-node/</id>
        <link href="https://chriswsq.github.io/post/xuperchian-change-Common-node/">
        </link>
        <updated>2020-09-15T11:19:03.000Z</updated>
        <content type="html"><![CDATA[<h1 id="加入群组">加入群组</h1>
<h2 id="查看当前群组节点">查看当前群组节点</h2>
<pre><code class="language-bash">./xchain-cli wasm query group_chain --method listNode -a '{&quot;bcname&quot;:&quot;app000120200824165811835422&quot;}'
</code></pre>
<h2 id="节点加入群组">节点加入群组</h2>
<pre><code class="language-bash">./xchain-cli wasm invoke group_chain --method addNode -a '{&quot;bcname&quot;:&quot;app000120200824165811835422&quot;, &quot;ip&quot;:&quot;/ip4/192.168.40.6/tcp/40001/p2p/QmY7UxwcLpD8QK8p6gAk99xuz3Q16jcaCoU8iMokVWYa83&quot;, &quot;address&quot;:&quot;2B1rDQhq7W4TStSHoD88N1SUYXrCDV821v&quot;}'
</code></pre>
<blockquote>
<p>将bcname 、ip 、 address改为实际的参数即可</p>
</blockquote>
<h1 id="更改共识节点">更改共识节点</h1>
<h2 id="查询金额">查询金额</h2>
<pre><code class="language-bash">./xchain-cli account balance zALW2YRp55LFuro1uAjgfoGTqCjgz3nHc --name app000120200824165811835422
</code></pre>
<h2 id="查看块高">查看块高</h2>
<pre><code class="language-bash">./xchain-cli status -H 127.0.0.1:37101 | jq '.blockchains[] | {&quot;name&quot;:.name,&quot;height&quot;:.ledger.trunkHeight}' | grep -A 1 app000120200824165811835422
</code></pre>
<h2 id="提案">提案</h2>
<pre><code class="language-bash">./xchain-cli transfer --to scocy5ZTaFykhRGGYxN9KSEkpxCD1cd72 --desc proposal_app000120200824165811835422.json  --amount 1  --name app000120200824165811835422

ae074dc967e0a03b81346a8e4796b01fe15b51472d3ba34f191d6b08e24a1918
</code></pre>
<h2 id="投票">投票</h2>
<pre><code class="language-bash">./xchain-cli vote ae074dc967e0a03b81346a8e4796b01fe15b51472d3ba34f191d6b08e24a1918 --frozen 138160 --amount 52000000071795360000   --name app000120200824165811835422

74217bf729af8fc1b6acfbc5f953fbda029fb9078360ec301dfc113e690ac016
</code></pre>
<h2 id="查看交易内容">查看交易内容</h2>
<pre><code class="language-bash">./xchain-cli tx query  74217bf729af8fc1b6acfbc5f953fbda029fb9078360ec301dfc113e690ac016
</code></pre>
<h2 id="查看共识节点">查看共识节点</h2>
<pre><code class="language-bash">./xchain-cli tdpos status --name   app000120200824165811835422
</code></pre>
<h1 id="提案内容">提案内容</h1>
<pre><code class="language-json">{
    &quot;module&quot;: &quot;proposal&quot;,
    &quot;method&quot;: &quot;Propose&quot;,
    &quot;args&quot; : {
        &quot;min_vote_percent&quot;: 51,
        &quot;stop_vote_height&quot;: 688970
    },
    &quot;trigger&quot;: {
        &quot;height&quot;: 688980,
        &quot;module&quot;: &quot;consensus&quot;,
        &quot;method&quot;: &quot;update_consensus&quot;,
        &quot;args&quot; : {
            &quot;name&quot;: &quot;tdpos&quot;,
            &quot;config&quot;: {
                &quot;version&quot;:&quot;20&quot;,
                &quot;proposer_num&quot;:&quot;2&quot;,
                &quot;period&quot;:&quot;5000&quot;,
                &quot;alternate_interval&quot;:&quot;5000&quot;,
                &quot;term_interval&quot;:&quot;10000&quot;,
                &quot;block_num&quot;:&quot;720&quot;,
                &quot;vote_unit_price&quot;:&quot;1&quot;,
                &quot;init_proposer&quot;: {
                    &quot;1&quot;:[&quot;scocy5ZTaFykhRGGYxN9KSEkpxCD1cd72&quot;, &quot;qaXhH7gJcdfpapmWkbHdLNqUFq3Vst6Am&quot;]
                }
            }
        }
    }
}
</code></pre>
<blockquote>
<p>注意： 以上将 address、p2p、proposer_num等改为实际数据即可<br>
命令添加群组，一次性添加两个以上群组 不生效,须一个一个添加<br>
用命令行创建平行链，如果命令写错不报命令的错误，而会报其他的问题    例如 地址不在白名单<br>
后续加入群组的节点，需要重启才会同步块数据<br>
在进行提案的时候经常会导致xuper链或其他调整的链快高不一致的情况，这时候重启解决问题<br>
如果同一个链既要增加节点又要删减节点，那么是需要分开提案来做的</p>
</blockquote>
<pre><code class="language-bash">new
pJsfQecriScf4ZA6MHhjEpMMAiBbct5Sv
24rqLhCMozBJrmsXhtrR68wLAr72zDfuEL
qJV7qfGdf2GAZUcrx6v71ahQ69nYYWGpa


huainan2
app0001202007302056480751681 

2A8cTP6dFjKoZPXyCx7T5APbQKCUzbgBsx
pecX9eVDd368J3GBfdPNtVUgnTu4nvD7b
28HsYtaS1p7DqZ3QqXzCSsEk47dX4seU6o

app0001202007310000590617583

2A8cTP6dFjKoZPXyCx7T5APbQKCUzbgBsx
27xoBigJ6HRqtqQtohvaoMyBt55uECtNbV
sMbiWCdbiAHn84p77zjepAzGn3F7ztzAD


app0001202008011331415497000
2A8cTP6dFjKoZPXyCx7T5APbQKCUzbgBsx
pecX9eVDd368J3GBfdPNtVUgnTu4nvD7b
qaXhH7gJcdfpapmWkbHdLNqUFq3Vst6Am




</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker容器保持后台运行的两种方式]]></title>
        <id>https://chriswsq.github.io/post/docker-rong-qi-bao-chi-hou-tai-yun-xing-de-liang-chong-fang-shi/</id>
        <link href="https://chriswsq.github.io/post/docker-rong-qi-bao-chi-hou-tai-yun-xing-de-liang-chong-fang-shi/">
        </link>
        <updated>2020-09-14T08:39:50.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<p>有的服务支持服务后台运行，那么在用docker启动服务时可以使用前台运行的命令，除此之外一些服务器是不支持前台运行，那么就要靠其他方式使用进程挂在前台。</p>
<ul>
<li>方法1 ，run一个容器：</li>
</ul>
<pre><code class="language-bash">[root@localhost ~]# docker run -dit --hostname centos --name centos --restart always a8493f5f50ff /bin/bash
 
-dit 是后台运行、交互模式、分配终端，容器启动后不会退出
 如果没有it参数，run 一个容器以后，docker ps -a 容器状态就exited了
--restart always 容器可以随docker服务启动而启动
</code></pre>
<ul>
<li>方法2， run 一个容器，并一直发送ping包</li>
</ul>
<pre><code class="language-bash">[root@localhost ~]# docker run -d --name test --hostname test a8493f5f50ff ping 127.0.0.1
</code></pre>
<p>这样容器就一直在发送ping包，不会退出。<br>
意思就是然容器一直运行一个程序，不退出，容器就不会停止</p>
<p>本文链接地址 https://www.rootop.org/pages/3736.html</p>
]]></content>
    </entry>
</feed>
<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://chriswsq.github.io</id>
    <title>chris&apos;wang</title>
    <updated>2020-09-10T09:52:18.807Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://chriswsq.github.io"/>
    <link rel="self" href="https://chriswsq.github.io/atom.xml"/>
    <subtitle>当你觉得无所事事时，那你就是在虚度光阴</subtitle>
    <logo>https://chriswsq.github.io/images/avatar.png</logo>
    <icon>https://chriswsq.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, chris&apos;wang</rights>
    <entry>
        <title type="html"><![CDATA[记一次服务器内存过高问题]]></title>
        <id>https://chriswsq.github.io/post/ji-yi-ci-fu-wu-qi-nei-cun-guo-gao-wen-ti/</id>
        <link href="https://chriswsq.github.io/post/ji-yi-ci-fu-wu-qi-nei-cun-guo-gao-wen-ti/">
        </link>
        <updated>2020-09-10T09:40:31.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<p>监控系统发邮件告警，一台服务器内存过高，已达 90% 以上，之前这台机器内存就高到85%以上，上去看了下服务正常 top 指令看了下没什么太高的进程占用，就重启了下上面的服务（前提是上面的服务重启是没什么影响的）。</p>
<p>今天有来告警了，内存占用率已经到90%，照常上去看了下<br>
使用 free -m 查看内存，一共是16G  已经用了 13G<br>
top  查看进程占用资源情况，发现最高的应用占用也不过百分之五左右</p>
<p>怀疑是被攻击了，看了下进程  ps  aux<br>
发现进程很多   ps aux |wc  -l    进程都6000多了，大部分的进程都是 sshd: root@notty  的进程，网上查了下这是被 ssh 暴力破解了，很奇怪，端口号改了不是22 了 ，攻击者怎么知道的呢。。。。</p>
<p>先解决问题吧</p>
<pre><code class="language-bash"> for i in  `ps  aux | grep root@notty | more | awk  '{print $2}'` ;do echo $i ;done
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker部署Prometheus监控服务器及容器并发送告警]]></title>
        <id>https://chriswsq.github.io/post/docker-bu-shu-prometheus-jian-kong-fu-wu-qi-ji-rong-qi-bing-fa-song-gao-jing/</id>
        <link href="https://chriswsq.github.io/post/docker-bu-shu-prometheus-jian-kong-fu-wu-qi-ji-rong-qi-bing-fa-song-gao-jing/">
        </link>
        <updated>2020-09-03T02:44:39.000Z</updated>
        <summary type="html"><![CDATA[<p>记录一下利用prometheus监控服务器信息和容器服务并发送邮件告警</p>
]]></summary>
        <content type="html"><![CDATA[<p>记录一下利用prometheus监控服务器信息和容器服务并发送邮件告警</p>
<!-- more -->
<h2 id="基本原理">基本原理</h2>
<p>Prometheus的基本原理是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。输出被监控组件信息的HTTP接口被叫做exporter 。目前互联网公司常用的组件大部分都有exporter可以直接使用，比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息(包括磁盘、内存、CPU、网络等等)。</p>
<h2 id="相关组件">相关组件</h2>
<ul>
<li>Prometheus: Prometheus Daemon负责定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。</li>
<li>Grafana: 接入prometheus数据，图形化展示监控信息</li>
<li>Node-exporter: 负责收集 host 硬件和操作系统数据。它将以容器方式运行在所有 host 上。</li>
<li>Cadvisor: 负责收集容器数据。它将以容器方式运行在所有 host 上。</li>
<li>Alertmanager: 警告管理器，用来进行报警。</li>
</ul>
<table>
<thead>
<tr>
<th>主机名</th>
<th>ip</th>
<th>服务</th>
</tr>
</thead>
<tbody>
<tr>
<td>test-1</td>
<td>192.168.40.6</td>
<td>cadvisor、node-exporter、grafana、prometheus、alertmanager.yml</td>
</tr>
<tr>
<td>test-2</td>
<td>192.168.40.7</td>
<td>node-exporter、cadvisor</td>
</tr>
<tr>
<td>test-3</td>
<td>192.168.40.8</td>
<td>node-exporter、cadvisor</td>
</tr>
</tbody>
</table>
<h2 id="安装docker-docker-compose">安装docker、docker-compose</h2>
<h3 id="安装docker">安装docker</h3>
<pre><code class="language-bash"># 安装依赖包
yum install -y yum-utils device-mapper-persistent-data lvm2
# 添加Docker软件包源
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
# 安装Docker CE
yum install docker-ce -y
# 启动
systemctl start docker
# 开机启动
systemctl enable docker
# 查看Docker信息
docker info
</code></pre>
<h3 id="安装docker-compose">安装docker-compose</h3>
<pre><code class="language-bash">curl -L https://github.com/docker/compose/releases/download/1.23.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
</code></pre>
<h2 id="添加配置文件">添加配置文件</h2>
<pre><code class="language-bash">mkdir -p /usr/local/src/config
cd /usr/local/src/config
</code></pre>
<h3 id="添加prometheusyml配置文件">添加prometheus.yml配置文件</h3>
<p>vim prometheus.yml</p>
<pre><code class="language-bash"># my global config
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
  - static_configs:
    - targets:
       - 192.168.40.6:9093

rule_files:
  - &quot;/etc/prometheus/config/rule/*rule.yml&quot;

scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 5s
    static_configs:
        - targets: ['192.168.40.6:9090']

  - job_name: 'cadvisor'
    scrape_interval: 5s
    static_configs:
        - targets: ['192.168.40.6:8080', '192.168.40.7:8080', '192.168.40.8']

  - job_name: 'node-exporter'
    scrape_interval: 5s
    static_configs:
        - targets: ['192.168.40.6:9100']
          labels:
            instance: test-1 - 192.168.40.6
            service: node-service
        - targets: ['192.168.40.7:9100']
          labels:
            instance: test-2 - 192.168.40.7
            service: node-service
        - targets: ['192.168.40.8:9100']
          labels:
            instance: test-3 - 192.168.40.8
            service: node-service
</code></pre>
<h3 id="添加邮件告警配置文件">添加邮件告警配置文件</h3>
<p>添加配置文件alertmanager.yml，配置收发邮件邮箱<br>
vim alertmanager.yml</p>
<pre><code class="language-bash">global:
  # The smarthost and SMTP sender used for mail notifications.  用于邮件通知的智能主机和SMTP发件人。
  smtp_smarthost: 'smtp.163.com:25'
  smtp_from: 'xxxxxxxxx@163.com'
  smtp_auth_username: 'xxxxxxxxxxxxxxx@163.com'
  smtp_auth_password: 'xxxxxxxxxxxxx'
  # The auth token for Hipchat.    Hipchat的身份验证令牌。

templates:
  - '/etc/alertmanager/default-monitor.tmpl'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 5m
  receiver: 'mail'


receivers:
- name: 'mail'
  email_configs:
  - to: 'xxxxxxxxxxxxxxxx@163.com, xxxxxxxxxxxxxx@qq.com'
    send_resolved: true #告警恢复通知
    html: '{{ template &quot;default-monitor.html&quot; . }}'  #应用那个模板
    headers: { Subject: &quot;[WARN] 报警邮件&quot; } #邮件主题信息 如果不写headers也可以在模板中定义默认加载email.default.subject这个模板
</code></pre>
<h3 id="添加报警规则">添加报警规则</h3>
<pre><code class="language-bash">mkdir -p /usr/local/src/config/rule
cd /usr/local/src/config/rule
</code></pre>
<p>创建两个文件</p>
<p>node-exporter-record-rule.yml<br>
node-exporter-alert-rule.yml</p>
<p>第一个文件用于记录规则，第二个是报警规则。<br>
由于之前我们在prometheus.yml中已经引用了所有已rule结尾的文件，所以我们不用在修改prometheus.yml配置文件。</p>
<p>创建node-exporter-record-rule.yml</p>
<pre><code class="language-bash">groups:
  - name: node-exporter-record
    rules:
    - expr: up{job=~&quot;node-exporter&quot;}
      record: node_exporter:up
      labels:
        desc: &quot;节点是否在线, 在线1,不在线0&quot;
        unit: &quot; &quot;
        job: &quot;node-exporter&quot;
    - expr: time() - node_boot_time_seconds{}
      record: node_exporter:node_uptime
      labels:
        desc: &quot;节点的运行时间&quot;
        unit: &quot;s&quot;
        job: &quot;node-exporter&quot;
##############################################################################################
#                              cpu                                                           #
    - expr: (1 - avg by (environment,instance) (irate(node_cpu_seconds_total{job=&quot;node-exporter&quot;,mode=&quot;idle&quot;}[5m])))  * 100
      record: node_exporter:cpu:total:percent
      labels:
        desc: &quot;节点的cpu总消耗百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;

    - expr: (avg by (environment,instance) (irate(node_cpu_seconds_total{job=&quot;node-exporter&quot;,mode=&quot;idle&quot;}[5m])))  * 100
      record: node_exporter:cpu:idle:percent
      labels:
        desc: &quot;节点的cpu idle百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;

    - expr: (avg by (environment,instance) (irate(node_cpu_seconds_total{job=&quot;node-exporter&quot;,mode=&quot;iowait&quot;}[5m])))  * 100
      record: node_exporter:cpu:iowait:percent
      labels:
        desc: &quot;节点的cpu iowait百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;


    - expr: (avg by (environment,instance) (irate(node_cpu_seconds_total{job=&quot;node-exporter&quot;,mode=&quot;system&quot;}[5m])))  * 100
      record: node_exporter:cpu:system:percent
      labels:
        desc: &quot;节点的cpu system百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;

    - expr: (avg by (environment,instance) (irate(node_cpu_seconds_total{job=&quot;node-exporter&quot;,mode=&quot;user&quot;}[5m])))  * 100
      record: node_exporter:cpu:user:percent
      labels:
        desc: &quot;节点的cpu user百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;

    - expr: (avg by (environment,instance) (irate(node_cpu_seconds_total{job=&quot;node-exporter&quot;,mode=~&quot;softirq|nice|irq|steal&quot;}[5m])))  * 100
      record: node_exporter:cpu:other:percent
      labels:
        desc: &quot;节点的cpu 其他的百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;
##############################################################################################


##############################################################################################
#                                    memory                                                  #
    - expr: node_memory_MemTotal_bytes{job=&quot;node-exporter&quot;}
      record: node_exporter:memory:total
      labels:
        desc: &quot;节点的内存总量&quot;
        unit: byte
        job: &quot;node-exporter&quot;

    - expr: node_memory_MemFree_bytes{job=&quot;node-exporter&quot;}
      record: node_exporter:memory:free
      labels:
        desc: &quot;节点的剩余内存量&quot;
        unit: byte
        job: &quot;node-exporter&quot;

    - expr: node_memory_MemTotal_bytes{job=&quot;node-exporter&quot;} - node_memory_MemFree_bytes{job=&quot;node-exporter&quot;}
      record: node_exporter:memory:used
      labels:
        desc: &quot;节点的已使用内存量&quot;
        unit: byte
        job: &quot;node-exporter&quot;

    - expr: node_memory_MemTotal_bytes{job=&quot;node-exporter&quot;} - node_memory_MemAvailable_bytes{job=&quot;node-exporter&quot;}
      record: node_exporter:memory:actualused
      labels:
        desc: &quot;节点用户实际使用的内存量&quot;
        unit: byte
        job: &quot;node-exporter&quot;

    - expr: (1-(node_memory_MemAvailable_bytes{job=&quot;node-exporter&quot;} / (node_memory_MemTotal_bytes{job=&quot;node-exporter&quot;})))* 100
      record: node_exporter:memory:used:percent
      labels:
        desc: &quot;节点的内存使用百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;

    - expr: ((node_memory_MemAvailable_bytes{job=&quot;node-exporter&quot;} / (node_memory_MemTotal_bytes{job=&quot;node-exporter&quot;})))* 100
      record: node_exporter:memory:free:percent
      labels:
        desc: &quot;节点的内存剩余百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;
##############################################################################################
#                                   load                                                     #
    - expr: sum by (instance) (node_load1{job=&quot;node-exporter&quot;})
      record: node_exporter:load:load1
      labels:
        desc: &quot;系统1分钟负载&quot;
        unit: &quot; &quot;
        job: &quot;node-exporter&quot;

    - expr: sum by (instance) (node_load5{job=&quot;node-exporter&quot;})
      record: node_exporter:load:load5
      labels:
        desc: &quot;系统5分钟负载&quot;
        unit: &quot; &quot;
        job: &quot;node-exporter&quot;

    - expr: sum by (instance) (node_load15{job=&quot;node-exporter&quot;})
      record: node_exporter:load:load15
      labels:
        desc: &quot;系统15分钟负载&quot;
        unit: &quot; &quot;
        job: &quot;node-exporter&quot;

##############################################################################################
#                                 disk                                                       #
    - expr: node_filesystem_size_bytes{job=&quot;node-exporter&quot; ,fstype=~&quot;ext4|xfs&quot;}
      record: node_exporter:disk:usage:total
      labels:
        desc: &quot;节点的磁盘总量&quot;
        unit: byte
        job: &quot;node-exporter&quot;

    - expr: node_filesystem_avail_bytes{job=&quot;node-exporter&quot;,fstype=~&quot;ext4|xfs&quot;}
      record: node_exporter:disk:usage:free
      labels:
        desc: &quot;节点的磁盘剩余空间&quot;
        unit: byte
        job: &quot;node-exporter&quot;

    - expr: node_filesystem_size_bytes{job=&quot;node-exporter&quot;,fstype=~&quot;ext4|xfs&quot;} - node_filesystem_avail_bytes{job=&quot;node-exporter&quot;,fstype=~&quot;ext4|xfs&quot;}
      record: node_exporter:disk:usage:used
      labels:
        desc: &quot;节点的磁盘使用的空间&quot;
        unit: byte
        job: &quot;node-exporter&quot;

    - expr:  (1 - node_filesystem_avail_bytes{job=&quot;node-exporter&quot;,fstype=~&quot;ext4|xfs&quot;} / node_filesystem_size_bytes{job=&quot;node-exporter&quot;,fstype=~&quot;ext4|xfs&quot;}) * 100
      record: node_exporter:disk:used:percent
      labels:
        desc: &quot;节点的磁盘的使用百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;

    - expr: irate(node_disk_reads_completed_total{job=&quot;node-exporter&quot;}[1m])
      record: node_exporter:disk:read:count:rate
      labels:
        desc: &quot;节点的磁盘读取速率&quot;
        unit: &quot;次/秒&quot;
        job: &quot;node-exporter&quot;

    - expr: irate(node_disk_writes_completed_total{job=&quot;node-exporter&quot;}[1m])
      record: node_exporter:disk:write:count:rate
      labels:
        desc: &quot;节点的磁盘写入速率&quot;
        unit: &quot;次/秒&quot;
        job: &quot;node-exporter&quot;

    - expr: (irate(node_disk_written_bytes_total{job=&quot;node-exporter&quot;}[1m]))/1024/1024
      record: node_exporter:disk:read:mb:rate
      labels:
        desc: &quot;节点的设备读取MB速率&quot;
        unit: &quot;MB/s&quot;
        job: &quot;node-exporter&quot;

    - expr: (irate(node_disk_read_bytes_total{job=&quot;node-exporter&quot;}[1m]))/1024/1024
      record: node_exporter:disk:write:mb:rate
      labels:
        desc: &quot;节点的设备写入MB速率&quot;
        unit: &quot;MB/s&quot;
        job: &quot;node-exporter&quot;

##############################################################################################
#                                filesystem                                                  #
    - expr:   (1 -node_filesystem_files_free{job=&quot;node-exporter&quot;,fstype=~&quot;ext4|xfs&quot;} / node_filesystem_files{job=&quot;node-exporter&quot;,fstype=~&quot;ext4|xfs&quot;}) * 100
      record: node_exporter:filesystem:used:percent
      labels:
        desc: &quot;节点的inode的剩余可用的百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;
#############################################################################################
#                                filefd                                                     #
    - expr: node_filefd_allocated{job=&quot;node-exporter&quot;}
      record: node_exporter:filefd_allocated:count
      labels:
        desc: &quot;节点的文件描述符打开个数&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;

    - expr: node_filefd_allocated{job=&quot;node-exporter&quot;}/node_filefd_maximum{job=&quot;node-exporter&quot;} * 100
      record: node_exporter:filefd_allocated:percent
      labels:
        desc: &quot;节点的文件描述符打开百分比&quot;
        unit: &quot;%&quot;
        job: &quot;node-exporter&quot;

#############################################################################################
#                                network                                                    #
    - expr: avg by (environment,instance,device) (irate(node_network_receive_bytes_total{device=~&quot;eth0|eth1|ens33|ens37&quot;}[1m]))
      record: node_exporter:network:netin:bit:rate
      labels:
        desc: &quot;节点网卡eth0每秒接收的比特数&quot;
        unit: &quot;bit/s&quot;
        job: &quot;node-exporter&quot;

    - expr: avg by (environment,instance,device) (irate(node_network_transmit_bytes_total{device=~&quot;eth0|eth1|ens33|ens37&quot;}[1m]))
      record: node_exporter:network:netout:bit:rate
      labels:
        desc: &quot;节点网卡eth0每秒发送的比特数&quot;
        unit: &quot;bit/s&quot;
        job: &quot;node-exporter&quot;

    - expr: avg by (environment,instance,device) (irate(node_network_receive_packets_total{device=~&quot;eth0|eth1|ens33|ens37&quot;}[1m]))
      record: node_exporter:network:netin:packet:rate
      labels:
        desc: &quot;节点网卡每秒接收的数据包个数&quot;
        unit: &quot;个/秒&quot;
        job: &quot;node-exporter&quot;

    - expr: avg by (environment,instance,device) (irate(node_network_transmit_packets_total{device=~&quot;eth0|eth1|ens33|ens37&quot;}[1m]))
      record: node_exporter:network:netout:packet:rate
      labels:
        desc: &quot;节点网卡发送的数据包个数&quot;
        unit: &quot;个/秒&quot;
        job: &quot;node-exporter&quot;

    - expr: avg by (environment,instance,device) (irate(node_network_receive_errs_total{device=~&quot;eth0|eth1|ens33|ens37&quot;}[1m]))
      record: node_exporter:network:netin:error:rate
      labels:
        desc: &quot;节点设备驱动器检测到的接收错误包的数量&quot;
        unit: &quot;个/秒&quot;
        job: &quot;node-exporter&quot;

    - expr: avg by (environment,instance,device) (irate(node_network_transmit_errs_total{device=~&quot;eth0|eth1|ens33|ens37&quot;}[1m]))
      record: node_exporter:network:netout:error:rate
      labels:
        desc: &quot;节点设备驱动器检测到的发送错误包的数量&quot;
        unit: &quot;个/秒&quot;
        job: &quot;node-exporter&quot;

    - expr: node_tcp_connection_states{job=&quot;node-exporter&quot;, state=&quot;established&quot;}
      record: node_exporter:network:tcp:established:count
      labels:
        desc: &quot;节点当前established的个数&quot;
        unit: &quot;个&quot;
        job: &quot;node-exporter&quot;

    - expr: node_tcp_connection_states{job=&quot;node-exporter&quot;, state=&quot;time_wait&quot;}
      record: node_exporter:network:tcp:timewait:count
      labels:
        desc: &quot;节点timewait的连接数&quot;
        unit: &quot;个&quot;
        job: &quot;node-exporter&quot;

    - expr: sum by (environment,instance) (node_tcp_connection_states{job=&quot;node-exporter&quot;})
      record: node_exporter:network:tcp:total:count
      labels:
        desc: &quot;节点tcp连接总数&quot;
        unit: &quot;个&quot;
        job: &quot;node-exporter&quot;

#############################################################################################
#                                process                                                    #
    - expr: node_processes_state{state=&quot;Z&quot;}
      record: node_exporter:process:zoom:total:count
      labels:
        desc: &quot;节点当前状态为zoom的个数&quot;
        unit: &quot;个&quot;
        job: &quot;node-exporter&quot;
#############################################################################################
#                                other                                                    #
    - expr: abs(node_timex_offset_seconds{job=&quot;node-exporter&quot;})
      record: node_exporter:time:offset
      labels:
        desc: &quot;节点的时间偏差&quot;
        unit: &quot;s&quot;
        job: &quot;node-exporter&quot;

#############################################################################################

    - expr: count by (instance) ( count by (instance,cpu) (node_cpu_seconds_total{ mode='system'}) )
      record: node_exporter:cpu:count
</code></pre>
<p>创建node-exporter-alert-rule.yml</p>
<pre><code class="language-bash">groups:
  - name: node-exporter-alert
    rules:
    - alert: node-exporter-down
      expr: node_exporter:up == 0
      for: 1m
      labels:
        severity: 'critical'
      annotations:
        summary: &quot;instance: {{ $labels.instance }} 宕机了&quot;
        description: &quot;instance: {{ $labels.instance }} \n- job: {{ $labels.job }} 关机了， 时间已经1分钟了。&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;



    - alert: node-exporter-cpu-high
      expr:  node_exporter:cpu:total:percent &gt; 80
      for: 3m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} cpu 使用率高于 {{ $value }}&quot;
        description: &quot;instance: {{ $labels.instance }} \n- job: {{ $labels.job }} CPU使用率已经持续三分钟高过80% 。&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;

    - alert: node-exporter-cpu-iowait-high
      expr:  node_exporter:cpu:iowait:percent &gt;= 12
      for: 3m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} cpu iowait 使用率高于 {{ $value }}&quot;
        description: &quot;instance: {{ $labels.instance }} \n- job: {{ $labels.job }} cpu iowait使用率已经持续三分钟高过12%&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-load-load1-high
      expr:  (node_exporter:load:load1) &gt; (node_exporter:cpu:count) * 1.2
      for: 3m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} load1 使用率高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-memory-high
      expr:  node_exporter:memory:used:percent &gt; 85
      for: 3m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} memory 使用率高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-disk-high
      expr:  node_exporter:disk:used:percent &gt; 88
      for: 10m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} disk 使用率高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-disk-read:count-high
      expr:  node_exporter:disk:read:count:rate &gt; 3000
      for: 2m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} iops read 使用率高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-disk-write-count-high
      expr:  node_exporter:disk:write:count:rate &gt; 3000
      for: 2m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} iops write 使用率高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;





    - alert: node-exporter-disk-read-mb-high
      expr:  node_exporter:disk:read:mb:rate &gt; 60
      for: 2m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} 读取字节数 高于 {{ $value }}&quot;
        description: &quot;&quot;
        instance: &quot;{{ $labels.instance }}&quot;
        value: &quot;{{ $value }}&quot;


    - alert: node-exporter-disk-write-mb-high
      expr:  node_exporter:disk:write:mb:rate &gt; 60
      for: 2m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} 写入字节数 高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-filefd-allocated-percent-high
      expr:  node_exporter:filefd_allocated:percent &gt; 80
      for: 10m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} 打开文件描述符 高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-network-netin-error-rate-high
      expr:  node_exporter:network:netin:error:rate &gt; 4
      for: 1m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} 包进入的错误速率 高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;

    - alert: node-exporter-network-netin-packet-rate-high
      expr:  node_exporter:network:netin:packet:rate &gt; 35000
      for: 1m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} 包进入速率 高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-network-netout-packet-rate-high
      expr:  node_exporter:network:netout:packet:rate &gt; 35000
      for: 1m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} 包流出速率 高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-network-tcp-total-count-high
      expr:  node_exporter:network:tcp:total:count &gt; 40000
      for: 1m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} tcp连接数量 高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-process-zoom-total-count-high
      expr:  node_exporter:process:zoom:total:count &gt; 10
      for: 10m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} 僵死进程数量 高于 {{ $value }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;


    - alert: node-exporter-time-offset-high
      expr:  node_exporter:time:offset &gt; 0.03
      for: 2m
      labels:
        severity: info
      annotations:
        summary: &quot;instance: {{ $labels.instance }} {{ $labels.desc }}  {{ $value }} {{ $labels.unit }}&quot;
        description: &quot;&quot;
        value: &quot;{{ $value }}&quot;
        instance: &quot;{{ $labels.instance }}&quot;
</code></pre>
<h3 id="添加告警模板">添加告警模板</h3>
<pre><code class="language-bash">mkdir  template
vim template/default-monitor.tmpl
</code></pre>
<pre><code class="language-tmpl">{{ define &quot;default-monitor.html&quot; }}
{{ range .Alerts }}
=========start==========&lt;br&gt;
告警程序: prometheus_alert &lt;br&gt;
告警级别: {{ .Labels.severity }} 级 &lt;br&gt;
告警类型: {{ .Labels.alertname }} &lt;br&gt;
故障主机: {{ .Labels.instance }} &lt;br&gt;
告警主题: {{ .Annotations.summary }} &lt;br&gt;
告警详情: {{ .Annotations.description }} &lt;br&gt;
触发时间: {{ .StartsAt.Format &quot;2019-08-04 16:58:15&quot; }} &lt;br&gt;
=========end==========&lt;br&gt;
{{ end }}
{{ end }}
</code></pre>
<h2 id="编写docker-compose文件">编写docker-compose文件</h2>
<p>vim    docker-compose-monitor.yml</p>
<pre><code class="language-yaml">version: '2'

networks:
    monitor:
        driver: bridge

services:
    prometheus:
        image: prom/prometheus
        container_name: prometheus
        hostname: prometheus
        restart: always
        volumes:
            - /usr/local/src/config/prometheus.yml:/etc/prometheus/prometheus.yml
            - /usr/local/src/config/rule:/etc/prometheus/config/rule
        ports:
            - &quot;9090:9090&quot;
        networks:
            - monitor

    alertmanager:
        image: prom/alertmanager
        container_name: alertmanager
        hostname: alertmanager
        restart: always
        volumes:
            - /usr/local/src/config/alertmanager.yml:/etc/alertmanager/alertmanager.yml
            - /usr/local/src/config/template/default-monitor.tmpl:/etc/alertmanager/default-monitor.tmpl
        ports:
            - &quot;9093:9093&quot;
        networks:
            - monitor

    grafana:
        image: grafana/grafana
        container_name: grafana
        hostname: grafana
        restart: always
        ports:
            - &quot;3000:3000&quot;
        networks:
            - monitor

    node-exporter:
        image: quay.io/prometheus/node-exporter
        container_name: node-exporter
        hostname: $HOSTNAME
        restart: always
        ports:
            - &quot;9100:9100&quot;
        volumes:
          - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro
          - /proc:/host/proc:ro
          - /sys:/host/sys:ro
          - /:/rootfs:ro
        restart: always
        command:
          - '--path.procfs=/host/proc'
          - '--path.sysfs=/host/sys'
          - '--path.rootfs=/rootfs'
        networks:
            - monitor

    cadvisor:
        image: google/cadvisor:latest
        container_name: cadvisor
        hostname: cadvisor
        restart: always
        volumes:
            - /:/rootfs:ro
            - /var/run:/var/run:rw
            - /sys:/sys:ro
            - /var/lib/docker/:/var/lib/docker:ro
        ports:
            - &quot;8080:8080&quot;
        networks:
            - monitor
</code></pre>
<h2 id="启动docker-compose">启动docker-compose</h2>
<pre><code class="language-bash">#启动容器：
docker-compose -f /usr/local/src/config/docker-compose-monitor.yml up -d
#删除容器：
docker-compose -f /usr/local/src/config/docker-compose-monitor.yml down
#重启容器：
docker restart id
</code></pre>
<p>在其他节点分别启动cadvisor和node-exporter容器</p>
<pre><code class="language-yaml">version: '2'

networks:
    monitor:
        driver: bridge

services:
    node-exporter:
        image: quay.io/prometheus/node-exporter
        container_name: node-exporter
        hostname: $HOSTNAME
        restart: always
        ports:
            - &quot;9100:9100&quot;
        volumes:
          - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro
          - /proc:/host/proc:ro
          - /sys:/host/sys:ro
          - /:/rootfs:ro
        restart: always
        command:
          - '--path.procfs=/host/proc'
          - '--path.sysfs=/host/sys'
          - '--path.rootfs=/rootfs'
        networks:
            - monitor
    cadvisor:
        image: google/cadvisor:latest
        container_name: cadvisor
        hostname: cadvisor
        restart: always
        volumes:
            - /:/rootfs:ro
            - /var/run:/var/run:rw
            - /sys:/sys:ro
            - /var/lib/docker/:/var/lib/docker:ro
        ports:
            - &quot;8080:8080&quot;
        networks:
            - monitor
</code></pre>
<p><strong>容器启动如下：</strong><br>
<img src="https://chriswsq.github.io/post-images/1599121054830.png" alt="" loading="lazy"></p>
<p><strong>prometheus targets界面如下：</strong><br>
<img src="https://chriswsq.github.io/post-images/1599121262766.png" alt="" loading="lazy"></p>
<blockquote>
<p>备注：如果State为Down，应该是防火墙问题，参考下面防火墙配置。</p>
</blockquote>
<p><strong>prometheus targets界面如下：</strong><br>
<img src="https://chriswsq.github.io/post-images/1599121408543.png" alt="" loading="lazy"></p>
<blockquote>
<p>备注：如果没有数据，同步下时间。</p>
</blockquote>
<h2 id="配置grafana">配置grafana</h2>
<h3 id="添加prometheus数据源">添加Prometheus数据源</h3>
<figure data-type="image" tabindex="1"><img src="https://chriswsq.github.io/post-images/1599121507210.png" alt="" loading="lazy"></figure>
<h3 id="配置dashboards">配置dashboards</h3>
<p><strong>说明：可以用自带模板，也可以去https://grafana.com/dashboards，下载对应的模板。</strong></p>
<p>添加监控服务器模板 此处用的模板id是   8919   也可使用（1860）</p>
<p><img src="https://chriswsq.github.io/post-images/1599121616143.png" alt="" loading="lazy"><br>
<img src="https://chriswsq.github.io/post-images/1599121699226.png" alt="" loading="lazy"><br>
<img src="https://chriswsq.github.io/post-images/1599121761143.png" alt="" loading="lazy"></p>
<p>添加监控容器模板   此处用  893   也可用（8321）</p>
<figure data-type="image" tabindex="2"><img src="https://chriswsq.github.io/post-images/1599122084044.png" alt="" loading="lazy"></figure>
<p>也可用综合的 9276</p>
<h2 id="告警">告警</h2>
<p>停止192.168.40.7 的 cadvisor和node-exporter容器<br>
<img src="https://chriswsq.github.io/post-images/1599122289244.png" alt="" loading="lazy"></p>
<p>收到告警邮件<br>
<img src="https://chriswsq.github.io/post-images/1599122330270.png" alt="" loading="lazy"></p>
<blockquote>
<p>注： 如果日期有问题则将告警模板的触发时间参数改为 <code>{{ .StartsAt.Format &quot;2019-08-04 16:58:15&quot; }} &lt;br&gt;</code> 即可。</p>
</blockquote>
<p>参考博客：<br>
https://juejin.im/post/6844903809517371406<br>
https://blog.csdn.net/w342164796/article/details/105079231/<br>
https://blog.csdn.net/aixiaoyang168/article/details/98474494</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s 如何关联pvc到特定的pv?]]></title>
        <id>https://chriswsq.github.io/post/k8s-ru-he-guan-lian-pvc-dao-te-ding-de-pv/</id>
        <link href="https://chriswsq.github.io/post/k8s-ru-he-guan-lian-pvc-dao-te-ding-de-pv/">
        </link>
        <updated>2020-08-27T05:59:30.000Z</updated>
        <summary type="html"><![CDATA[<p>部署有状态的应用时需要挂载相应的配置文件，了解下最常用的pv（nfs）和pvc绑定关系</p>
]]></summary>
        <content type="html"><![CDATA[<p>部署有状态的应用时需要挂载相应的配置文件，了解下最常用的pv（nfs）和pvc绑定关系</p>
<!-- more -->
<p>首先肯定要在放置配置文件的地方配置nfs服务</p>
<p>如何关联pvc到特定的pv?</p>
<p>我们可以使用对 pv 打 label 的方式，具体如下：</p>
<p>创建 pv，指定 label</p>
<p><code>cat nfs-test-pv.yaml</code></p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-test-pv
#  namespace: test-pv-test
  labels:
    pv: nfs-test-pv
spec:
  capacity:
    storage: 100Mi
  accessModes:
    - ReadWriteMany
  nfs:
    # FIXME: use the right IP
    server: 192.168.40.6
    path: &quot;/test/&quot;
</code></pre>
<p>然后创建 pvc，使用 matchLabel 来关联刚创建的 pv:nfs-test-pv</p>
<p><code>cat nfs-test-pvc.yaml</code></p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-test-pvc
#  namespace: test-pv-test
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: &quot;&quot;
  resources:
    requests:
      storage: 90Mi
  selector:
    matchLabels:
      pv: nfs-test-pv
</code></pre>
<p>下面开始测试：</p>
<p><strong>创建pv</strong></p>
<p><code>kubectl apply -f nfs-test-pv.yaml</code></p>
<p><strong>查看pv</strong></p>
<pre><code>kubectl get pv
[root@test-1 ~]# kubectl get pv
NAME         CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS   REASON   AGE
ca-service   100Mi      RWX            Retain           Bound    default/ca-service-pvc                           30m

</code></pre>
<p><strong>然后创建 pvc</strong><br>
<code>kubectl apply -f nfs-test-pvc.yaml</code></p>
<p><strong>查看pvc</strong></p>
<pre><code>[root@test-1 ~]# kubectl get pvc
NAME             STATUS   VOLUME       CAPACITY   ACCESS MODES   STORAGECLASS   AGE
ca-service-pvc   Bound    ca-service   100Mi      RWX                           30m
</code></pre>
<p>已都正确绑定</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s pv,pvc无法删除问题]]></title>
        <id>https://chriswsq.github.io/post/k8s-pvpvc-wu-fa-shan-chu-wen-ti/</id>
        <link href="https://chriswsq.github.io/post/k8s-pvpvc-wu-fa-shan-chu-wen-ti/">
        </link>
        <updated>2020-08-27T05:58:37.000Z</updated>
        <summary type="html"><![CDATA[<p>解决k8s pv,pvc无法删除问题</p>
]]></summary>
        <content type="html"><![CDATA[<p>解决k8s pv,pvc无法删除问题</p>
<!-- more -->
<p>一般删除步骤为：先删pod再删pvc最后删pv</p>
<p>但是遇到pv始终处于“Terminating”状态，而且delete不掉。如下：</p>
<pre><code class="language-bash">[root@test-1 pv]# kubectl get pv
NAME         CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS        CLAIM                    STORAGECLASS   REASON   AGE
ca-service   100Mi      RWX            Retain           Terminating   default/ca-service-pvc                           17h

</code></pre>
<p>解决方法：</p>
<p>直接删除k8s中的记录：</p>
<pre><code class="language-bash">kubectl patch pv ca-service  -p '{&quot;metadata&quot;:{&quot;finalizers&quot;:null}}'
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[kubeadm部署k8s]]></title>
        <id>https://chriswsq.github.io/post/kubeadm-bu-shu-k8s/</id>
        <link href="https://chriswsq.github.io/post/kubeadm-bu-shu-k8s/">
        </link>
        <updated>2020-08-27T05:56:13.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<h1 id="部署环境">部署环境</h1>
<table>
<thead>
<tr>
<th>主机名</th>
<th>centos版本</th>
<th>IP</th>
<th>docker-version</th>
<th>flanel-version</th>
<th>keepalived-version</th>
<th>主机配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>k8s-master1</td>
<td>7.4</td>
<td>192.168.40.6</td>
<td>18.09.9</td>
<td>v0.11.0</td>
<td>v1.3.5</td>
<td>2C4G</td>
</tr>
<tr>
<td>k8s-node1</td>
<td>7.4</td>
<td>192.168.40.7</td>
<td>18.09.9</td>
<td>v0.11.0</td>
<td>v1.3.5</td>
<td>2C4G</td>
</tr>
<tr>
<td>k8s-node2</td>
<td>7.4</td>
<td>192.168.40.8</td>
<td>18.09.9</td>
<td>v0.11.0</td>
<td>v1.3.5</td>
<td>2C4G</td>
</tr>
</tbody>
</table>
<p>二、高可用架构</p>
<figure data-type="image" tabindex="1"><img src="https://chriswsq.github.io/post-images/1598507860493.jpg" alt="" loading="lazy"></figure>
<p>注：此图为负载为loadbanacer为云上的负载方案</p>
<p>在此就说下本人在这里犯的小错误</p>
<p>1.拉镜像时各个节点都要拉取</p>
<p>2.部署flannel时因为网络的原因可以先down下载，在执行   kubectl apply -f   kube-flannel.yml<br>
wget https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml</p>
<p>3.部署后会发现主节点Ready 而从节点都是NotReady，这是因为master节点的这个文件 /etc/cni/net.d/10-flannel.conflist 是因为安装flannel生成的，而node节点是通过master分配生成的所以少一个参数<br>
&quot;cniVersion&quot;: &quot;0.3.1&quot;,</p>
<p>直接把maser推过去到node节点，或者手动改下就可以了</p>
<h2 id=""></h2>
<p>kubeadm部署</p>
<p>kubeadm join 192.168.154.6:6443 --token hum394.uf5ehv9ye6w661bz <br>
--discovery-token-ca-cert-hash sha256:6bd3388a191ae0afb2ca86102e655a2ced4c6e6b6bef82afebbdef8154a57b61</p>
<p>node</p>
<p>{<br>
&quot;name&quot;: &quot;cbr0&quot;,<br>
&quot;plugins&quot;: [<br>
{<br>
&quot;type&quot;: &quot;flannel&quot;,<br>
&quot;delegate&quot;: {<br>
&quot;hairpinMode&quot;: true,<br>
&quot;isDefaultGateway&quot;: true<br>
}<br>
},<br>
{<br>
&quot;type&quot;: &quot;portmap&quot;,<br>
&quot;capabilities&quot;: {<br>
&quot;portMappings&quot;: true<br>
}<br>
}<br>
]<br>
}</p>
<p>master</p>
<p>{<br>
&quot;name&quot;: &quot;cbr0&quot;,<br>
&quot;cniVersion&quot;: &quot;0.3.1&quot;,<br>
&quot;plugins&quot;: [<br>
{<br>
&quot;type&quot;: &quot;flannel&quot;,<br>
&quot;delegate&quot;: {<br>
&quot;hairpinMode&quot;: true,<br>
&quot;isDefaultGateway&quot;: true<br>
}<br>
},<br>
{<br>
&quot;type&quot;: &quot;portmap&quot;,<br>
&quot;capabilities&quot;: {<br>
&quot;portMappings&quot;: true<br>
}<br>
}<br>
]<br>
}</p>
<p>参考<br>
https://www.kubernetes.org.cn/6632.html</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[logstash配置]]></title>
        <id>https://chriswsq.github.io/post/logstash-pei-zhi/</id>
        <link href="https://chriswsq.github.io/post/logstash-pei-zhi/">
        </link>
        <updated>2020-08-27T05:54:19.000Z</updated>
        <summary type="html"><![CDATA[<p>补上一份自己在工作中用的一份logstash的配置文件，万变不离其宗，可以参看此内容</p>
]]></summary>
        <content type="html"><![CDATA[<p>补上一份自己在工作中用的一份logstash的配置文件，万变不离其宗，可以参看此内容</p>
<!-- more -->
<h2 id="这一份匹配的日志是前部分是字符串后一部分是json格式的日志">这一份匹配的日志是，前部分是字符串，后一部分是json格式的日志</h2>
<pre><code class="language-yml">input {
    kafka {
        bootstrap_servers =&gt; &quot;kafka1:9092, kafka2:9092, kafka3:9092&quot;
        topics =&gt; [&quot;tomcat&quot;]
        type =&gt; &quot;tomcat&quot;
        codec =&gt; json {
           charset =&gt; &quot;UTF-8&quot;
        }
    }
}

filter {     
   if [type] == &quot;tomcat&quot; {
   grok {
            match =&gt; { 'message' =&gt; '%{TIMESTAMP_ISO8601:access_time}  %{LOGLEVEL:loglevel} %{INT:number} --- \[%{DATA:thread_name}\] %{URIHOST:
type_name}  %{SPACE}*  : %{HOSTNAME:status} %{HOSTNAME:action} %{URIHOST:usetime}((?&lt;request&gt;(.*)(?=Creating)/?)|)(%{GREEDYDATA:sql}|)'}
}
   json {
        source =&gt; &quot;request&quot;
        #target =&gt; &quot;parsedJson&quot;
        remove_field=&gt;[&quot;request&quot;]
}      
    mutate {
        remove_field =&gt; [&quot;agent&quot;]
        remove_field =&gt; [&quot;[ecs][version]&quot;,&quot;[fields][log_topics]&quot;,&quot;[fields][registry_file]&quot;,&quot;[host][name]&quot;,&quot;[input][type]&quot;,&quot;[@version]&quot;,&quot;[tag]&quot;,&quot;[id]&quot;,&quot;[score]&quot;]
          }
     }
}
output {
  if [type] == &quot;tomcat&quot; {
  elasticsearch {
    hosts =&gt; [&quot;elasticsearch1:9200&quot;,&quot;elasticsearch2:9200&quot;,&quot;elasticsearch3:9200&quot;]
    index =&gt; &quot;tomcat-%{+YYYY.MM.dd}&quot;
    user =&gt; 'elastic'
    password =&gt; 'd27DuDQjTChIdv3sE8oI'
   }
 }
}
</code></pre>
<h2 id="这一份是整个的日志都是json格式">这一份是整个的日志都是json格式</h2>
<pre><code class="language-yml">input {
    kafka {
        bootstrap_servers =&gt; &quot;kafka1:9092, kafka2:9092, kafka3:9092&quot;
        topics =&gt; [&quot;gateway&quot;]
        type =&gt; &quot;gateway&quot;
        codec =&gt; json {
           charset =&gt; &quot;UTF-8&quot;
        }
    }
}
filter {
   if [type] == &quot;gateway&quot; {
    json {
        source =&gt; &quot;message&quot;
        #target =&gt; &quot;doc&quot;
        remove_field =&gt; [&quot;message&quot;]
    }        
    mutate {
        remove_field =&gt; [&quot;agent&quot;]
        remove_field =&gt; [&quot;[ecs][version]&quot;,&quot;[fields][log_topics]&quot;,&quot;[fields][registry_file]&quot;,&quot;[host][name]&quot;,&quot;[input][type]&quot;,&quot;[@version]&quot;,&quot;[tag]&quot;,&quot;[id]&quot;,&quot;[score]&quot;]
      } 
   }
}
output {
   if [type] == &quot;gateway&quot; {
    elasticsearch {
    hosts =&gt; [&quot;elasticsearch1:9200&quot;,&quot;elasticsearch2:9200&quot;,&quot;elasticsearch3:9200&quot;]
    index =&gt; &quot;gateway-%{+YYYY.MM.dd}&quot;
    user =&gt; 'elastic'
    password =&gt; 'd27DuDQjTChIdv3sE8oI'
        } 
    }
}
</code></pre>
<h2 id="这是一份整个日志都是字符串的格式">这是一份整个日志都是字符串的格式</h2>
<pre><code class="language-yml">input {
    kafka {
        bootstrap_servers =&gt; &quot;kafka1:9092, kafka2:9092, kafka3:9092&quot;
        topics =&gt; [&quot;gb_core_ngx&quot;]
        type =&gt; &quot;gb_core_ngx&quot;
        codec =&gt; json {
           charset =&gt; &quot;UTF-8&quot;
        }
    }
}
filter {
    if [type] == &quot;gb_core_ngx&quot; {

    grok {
       match =&gt; {
              &quot;message&quot; =&gt; &quot;%{URIHOST:hostname}: \[%{TIMESTAMP_ISO8601:local_time}\] (%{NUMBER:status}|-) %{NUMBER:siteid}-%{WORD:idc_num}-%{HOSTNAME:Random_value} (%{HOSTNAME:X_system}|-) *(%{URIHOST:remote_hostname}|-),%{URIHOST:outsite_hostname} \[(%{URIHOST:upstream_addr}|-)] %{NUMBER:request_time} (%{NUMBER:upstraem_response_time}|-) (%{WORD:request_method}|-) (%{HOSTNAME:http_host}|-) (%{GREEDYDATA:uri}|-) (%{NUMBER:body_bytes_sent}|-) \| (%{IPORHOST:client_ip}|-)&quot;
       }
}
    mutate {
        remove_field =&gt; &quot;tags&quot;
        remove_field =&gt; &quot;port&quot;
        remove_field =&gt; &quot;prospector&quot;
        remove_field =&gt; &quot;beat&quot;
        remove_field =&gt; &quot;source&quot;
        remove_field =&gt; &quot;offset&quot;
        remove_field =&gt; &quot;fields&quot;
        remove_field =&gt; &quot;host&quot;
        remove_field =&gt; &quot;@version&quot;
        remove_field =&gt; &quot;message&quot;
        remove_field =&gt; &quot;input&quot;
        convert =&gt; [&quot;body_bytes_sent&quot;, &quot;float&quot;]
        convert =&gt; [&quot;request_time&quot;, &quot;float&quot;]
        convert =&gt; [&quot;upstream_response_time&quot;, &quot;float&quot;]
        add_field =&gt; { &quot;uuid&quot; =&gt; &quot;%{siteid}-%{idc_num}-%{Random_value}&quot; }
    }

#    date {
#        match =&gt; [&quot;local__time&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;]
#}
   
   geoip {
        source =&gt; &quot;client_ip&quot;
        target =&gt; &quot;geoip&quot;
        database =&gt; &quot;/opt/GeoLite2-City.mmdb&quot;
        add_field =&gt; [&quot;[geoip][coordinates]&quot;,&quot;%{[geoip][longitude]}&quot;]
        add_field =&gt; [&quot;[geoip][coordinates]&quot;,&quot;%{[geoip][latitude]}&quot;]
                }
   mutate {
                 convert =&gt; [ &quot;[geoip][coordinates]&quot;, &quot;float&quot;]
        }
   }
}
output {
       if [type] == &quot;gb_core_ngx&quot; {
       elasticsearch { 
       hosts =&gt; [&quot;elasticsearch1:9200&quot; ,&quot;elasticsearch2:9200&quot;, &quot;elasticsearch3:9200&quot;]
       index =&gt; &quot;logstash-gb_core_ngx-%{+YYYY.MM.dd}&quot;
       user =&gt; 'elastic'
       password =&gt; 'd27DuDQjTChIdv3sE8oI'
   }
 }
}
</code></pre>
<h2 id="添加组合字段">添加&amp;组合字段</h2>
<pre><code class="language-yml">filter {
 grok {
    match =&gt; { &quot;message&quot; =&gt; '&quot;(%{GREEDYDATA:cust_date})&quot;,&quot;(%{TIME:cust_time})&quot;,&quot;(%{NUMBER:author})&quot;'}
    add_field =&gt; {
            &quot;date_time&quot; =&gt; &quot;%{cust_date};%{cust_time}&quot;
    }
}

date {
  match =&gt; [&quot;date_time&quot;, &quot;yyyy-MM-dd;hh:mm:ss&quot;]
  target =&gt; &quot;@timestamp&quot;
  add_field =&gt; { &quot;debug&quot; =&gt; &quot;timestampMatched&quot;}
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[elk用户认证问题]]></title>
        <id>https://chriswsq.github.io/post/elk-yong-hu-ren-zheng-wen-ti/</id>
        <link href="https://chriswsq.github.io/post/elk-yong-hu-ren-zheng-wen-ti/">
        </link>
        <updated>2020-08-27T05:52:58.000Z</updated>
        <summary type="html"><![CDATA[<p>elk7+的用户认证免费了，不过没有集成在安装包里，还需要自己再进行一些操作，在此记录下自己再配置用户认证时遇到的问题</p>
]]></summary>
        <content type="html"><![CDATA[<p>elk7+的用户认证免费了，不过没有集成在安装包里，还需要自己再进行一些操作，在此记录下自己再配置用户认证时遇到的问题</p>
<!-- more -->
<h2 id="开启安全功能">开启安全功能</h2>
<p>首先在es配置文件中开启安全功能</p>
<pre><code>.....

xpack.security.enabled: true
xpack.security.transport.ssl.enabled
</code></pre>
<p>然后重启es服务</p>
<h2 id="生成证书配置node间ssl通信">生成证书，配置Node间SSL通信</h2>
<h3 id="创建ca证书">创建ca证书</h3>
<pre><code>$ bin/elasticsearch-certutil ca -v
</code></pre>
<p>一路回车即可</p>
<p>默认的CA证书存放在$ES_HOME 目录中</p>
<p>这个命令生成格式为PKCS#12名称为 elastic-stack-ca.p12 的keystore文件，包含CA证书和私钥。</p>
<h3 id="创建节点间认证用的证书">创建节点间认证用的证书</h3>
<pre><code>$ ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 
</code></pre>
<p>一路回车即可</p>
<h3 id="配置es节点使用这个证书">配置ES节点使用这个证书</h3>
<pre><code>$ mkdir config/certs
$ mv elastic-* config/certs/
ll config/certs/

-rw------- 1 elasticsearch root 3443 Jun  9 15:22 elastic-certificates.p12
-rw------- 1 elasticsearch root 2527 Jun  9 15:22 elastic-stack-ca.p12
</code></pre>
<p>拷贝这个目录到所有的ES节点中<br>
config/certs 目录中不需要拷贝CA证书文件，只拷贝cert文件即可</p>
<p>配置elasticsearch.yml配置文件，注意所有的node节点都需要配置，这里的配置是使用PKCS#12格式的证书。</p>
<pre><code>$ vim  config/elasticsearch.yml
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.verification_mode: certificate #认证方式使用证书
xpack.security.transport.ssl.keystore.path: certs/elastic-certificates.p12
xpack.security.transport.ssl.truststore.path: certs/elastic-certificates.p12
</code></pre>
<h2 id="测试能够正常启动了-好了我们再来继续之前的生成密码在随意一台节点即可">测试能够正常启动了。好了，我们再来继续之前的生成密码：在随意一台节点即可。</h2>
<p>生成密码有两个命令，一个为自动生成，一个为手动生成</p>
<p>自动<br>
<code>bin/elasticsearch-setup-passwords auto</code><br>
手动<br>
<code>bin/elasticsearch-setup-passwords interactive</code></p>
<p>这里我们选择自动</p>
<pre><code>[root@elasticsearch1 elasticsearch]# bin/elasticsearch-setup-passwords auto
Initiating the setup of passwords for reserved users elastic,apm_system,kibana,logstash_system,beats_system,remote_monitoring_user.
The passwords will be randomly generated and printed to the console.
Please confirm that you would like to continue [y/N]y


Changed password for user apm_system
PASSWORD apm_system = EKPbqziKu4v3P0MYoYIJ

Changed password for user kibana
PASSWORD kibana = 48Sf7tIFArn4rmyMW2x4

Changed password for user logstash_system
PASSWORD logstash_system = O09XtxP495uNRxHRZxtC

Changed password for user beats_system
PASSWORD beats_system = ULC810uP0sVCAKhbwxvE

Changed password for user remote_monitoring_user
PASSWORD remote_monitoring_user = zqnO9YBFsoRu5QIsgOi6

Changed password for user elastic
PASSWORD elastic = d27DuDQjTChIdv3sE8oI

</code></pre>
<p>查看集群节点数量：</p>
<pre><code>[root@test-1 conf]# curl -u elastic 192.168.154.6:9200/_cat/nodes
Enter host password for user 'elastic':
10.0.0.67 32 88 1 0.12 0.08 0.43 ilmr   - node-1
10.0.0.92 14 80 1 0.12 0.07 0.22 dilmrt * node-2
10.0.0.93 12 79 1 0.00 0.03 0.24 dilmrt - node-3
</code></pre>
<h2 id="kibana的安装配置">kibana的安装配置</h2>
<h3 id="编辑配置文件">编辑配置文件</h3>
<pre><code>$ cat kibana/config/kibana.yml |grep -Ev &quot;^$|^#&quot;
server.port: 5601
server.host: &quot;0.0.0.0&quot;
server.name: &quot;mykibana&quot;
elasticsearch.hosts: [&quot;http://localhost:9200&quot;]
kibana.index: &quot;.kibana&quot;
elasticsearch.username: &quot;kibana&quot;
elasticsearch.password: &quot;UKuHceHWudloJk9NvHlX&quot;
# i18n.locale: &quot;en&quot;
i18n.locale: &quot;zh-CN&quot;
xpack.security.encryptionKey: Hz*9yFFaPejHvCkhT*ddNx%WsBgxVSCQ
</code></pre>
<h3 id="页面访问kibana">页面访问kibana</h3>
<figure data-type="image" tabindex="1"><img src="/images/elk%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81/kibana-login.jpg" alt="" loading="lazy"></figure>
<p>输入上面生成的管理员elastic的用户和密码，就可以登陆了，我们查看一下license许可吧：<br>
<img src="/images/elk%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81/kibana-basic.jpg" alt="" loading="lazy"></p>
<p>一个使用永不过期的Basic许可的免费License，开启了基本的Auth认证和集群间SSL/TLS 认证的Elasticsearch集群就创建完毕了。</p>
<p>等等，你有没有想过Kibana的配置文件中使用着明文的用户名密码，这里只能通过LInux的权限进行控制了，有没有更安全的方式呢，有的，就是keystore。</p>
<h3 id="kibana-keystore-安全配置">kibana keystore 安全配置</h3>
<p><a href="https://www.elastic.co/guide/en/kibana/7.7/secure-settings.html">参考官方</a></p>
<p>查看<code>kibana-keystore</code>命令帮助：</p>
<pre><code>$ ./bin/kibana-keystore --help
Usage: bin/kibana-keystore [options] [command]

A tool for managing settings stored in the Kibana keystore

Options:
  -V, --version           output the version number
  -h, --help              output usage information

Commands:
  create [options]        Creates a new Kibana keystore
  list [options]          List entries in the keystore
  add [options] &lt;key&gt;     Add a string setting to the keystore
  remove [options] &lt;key&gt;  Remove a setting from the keystore

</code></pre>
<p>首先我们创建keystore：</p>
<pre><code>$ bin/kibana-keystore create
Created Kibana keystore in /opt/elk74/kibana-7.4.2-linux-x86_64/data/kibana.keystore # 默认存放位置
</code></pre>
<p>增加配置：</p>
<p>我们要吧kibana.yml 配置文件中的敏感信息，比如：elasticsearch.username 和 elasticsearch.password，给隐藏掉，或者直接去掉；</p>
<p>所以这里我们增加两个配置：分别是elasticsearch.password 和 elasticsearch.username:</p>
<pre><code># 查看add的命令帮助：
$ ./bin/kibana-keystore add --help
Usage: add [options] &lt;key&gt;

Add a string setting to the keystore

Options:
  -f, --force   overwrite existing setting without prompting
  -x, --stdin   read setting value from stdin
  -s, --silent  prevent all logging
  -h, --help    output usage information

# 创建elasticsearch.username这个key：注意名字必须是kibana.yml中的key
$ ./bin/kibana-keystore add elasticsearch.username
Enter value for elasticsearch.username: ******  # 输入key对应的value，这里是kibana连接es的账号：kibana

# 创建elasticsearch.password这个key
$ ./bin/kibana-keystore add elasticsearch.password
Enter value for elasticsearch.password: ******************** # 输入对应的密码：UKuHceHWudloJk9NvHlX
</code></pre>
<p>好了，我们把kibana.yml配置文件中的这两项配置删除即可，然后直接启动kibana，kibana会自动已用这两个配置的。</p>
<p>最终的kibana.yml配置如下：</p>
<pre><code>server.port: 5601
server.host: &quot;0.0.0.0&quot;
server.name: &quot;mykibana&quot;
elasticsearch.hosts: [&quot;http://localhost:9200&quot;]
kibana.index: &quot;.kibana&quot;
# i18n.locale: &quot;en&quot;
i18n.locale: &quot;zh-CN&quot;
xpack.security.encryptionKey: Hz*9yFFaPejHvCkhT*ddNx%WsBgxVSCQ
</code></pre>
<p>这样配置文件中就不会出现敏感信息了，达到了更高的安全性。</p>
<p>类似的Keystore方式不只是Kibana支持，ELK的产品都是支持的。</p>
<p><strong>注意：两个证书文件属主须是启动用户，certs权限为744即可，权限不够会报错,其他节点权限也一样</strong></p>
<pre><code>elk_elasticsearch1.1.rqtnwnm1sqzw@test-1    | uncaught exception in thread [main]
elk_elasticsearch1.1.rqtnwnm1sqzw@test-1    | ElasticsearchSecurityException[failed to load SSL configuration [xpack.security.transport.ssl]]; nested: ElasticsearchException[failed to initialize SSL TrustManager - not permitted to read truststore file [/usr/share/elasticsearch/config/certs/elastic-certificates.p12]]; nested: AccessDeniedException[/usr/share/elasticsearch/config/certs/elastic-certificates.p12];
elk_elasticsearch1.1.jp9k598g34hq@test-1    | &quot;... 6 more&quot;] }
elk_elasticsearch1.1.yk71h6aom47z@test-1    | &quot;at org.elasticsearch.node.Node.&lt;init&gt;(Node.java:481) ~[elasticsearch-7.7.0.jar:7.7.0]&quot;,
elk_elasticsearch1.1.w26656n32a86@test-1    | &quot;... 6 more&quot;] }
elk_elasticsearch1.1.w26656n32a86@test-1    | ElasticsearchSecurityException[failed to load SSL configuration [xpack.security.transport.ssl]]; nested: ElasticsearchException[failed to initialize SSL TrustManager - not permitted to read truststore file [/usr/share/elasticsearch/config/certs/elastic-certificates.p12]]; nested: AccessDeniedException[/usr/share/elasticsearch/config/certs/elastic-certificates.p12];
elk_elasticsearch1.1.rqtnwnm1sqzw@test-1    | Likely root cause: java.nio.file.AccessDeniedException: /usr/share/elasticsearch/config/certs/elastic-certificates.p12
elk_elasticsearch1.1.jp9k598g34hq@test-1    | ElasticsearchSecurityException[failed to load SSL configuration [xpack.security.transport.ssl]]; nested: ElasticsearchException[failed to initialize SSL TrustManager - not permitted to read truststore file [/usr/share/elasticsearch/config/certs/elastic-certificates.p12]]; nested: AccessDeniedException[/usr/share/elasticsearch/config/certs/elastic-certificates.p12];
</code></pre>
<p><a href="https://knner.wang/2019/11/26/install-elasticsearch-cluster-7-4.html">参考自</a></p>
<h2 id="logstash配置">logstash配置</h2>
<p><a href="https://www.elastic.co/cn/blog/configuring-ssl-tls-and-https-to-secure-elasticsearch-kibana-beats-and-logstash">参考</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ELK告警之elastalert部署及配置]]></title>
        <id>https://chriswsq.github.io/post/elk-gao-jing-zhi-elastalert-bu-shu-ji-pei-zhi/</id>
        <link href="https://chriswsq.github.io/post/elk-gao-jing-zhi-elastalert-bu-shu-ji-pei-zhi/">
        </link>
        <updated>2020-08-27T05:51:57.000Z</updated>
        <summary type="html"><![CDATA[<p>ELK7版本的日志告警Elastalert配置</p>
]]></summary>
        <content type="html"><![CDATA[<p>ELK7版本的日志告警Elastalert配置</p>
<!-- more -->
<h1 id="安装elastalert">安装Elastalert</h1>
<h2 id="环境">环境</h2>
<ul>
<li>CentOS：7.6</li>
<li>Python：3.6.9</li>
<li>pip：19.3</li>
<li>elastalert：0.2.0</li>
<li>elk：7.7.0</li>
</ul>
<h2 id="配置python369环境">配置Python3.6.9环境</h2>
<p>安装依赖包<br>
<code>yum -y install wget openssl openssl-devel gcc gcc-c++</code></p>
<p>下载包<br>
<code>wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz</code></p>
<p>安装</p>
<pre><code>tar xf Python-3.6.9.tgz
cd Python-3.6.9./configure --prefix=/usr/local/python --with-openssl
make &amp;&amp; make install
</code></pre>
<p>配置</p>
<pre><code>mv /usr/bin/python /usr/bin/python_old
ln -s /usr/local/python/bin/python3 /usr/bin/python
ln -s /usr/local/python/bin/pip3 /usr/bin/pip
pip install --upgrade pip
</code></pre>
<p><strong>注意,所有依赖python2的脚本或者命令,需要更改为python2.7,因为现在默认的python版本为3.6,例如</strong></p>
<pre><code>sed -i '1s/python/python2.7/g' /usr/bin/yum
sed -i '1s/python/python2.7/g' /usr/libexec/urlgrabber-ext-down
</code></pre>
<p>验证</p>
<pre><code>$ python -V
    Python 3.6.9
$ pip -V 
	pip 19.3 from /usr/local/python/lib/python3.6/site-packages/pip (python 3.6).
</code></pre>
<h2 id="安装elastalert-2">安装elastalert</h2>
<p>下载包</p>
<pre><code>git clone https://github.com/Yelp/elastalert.git
cd elastalert
</code></pre>
<p>安装</p>
<pre><code>pip install &quot;elasticsearch&lt;7,&gt;6&quot;
pip install -r requirements.txt
python setup.py install
</code></pre>
<p>安装成功后可以看到四个命令</p>
<pre><code>ll /usr/local/python/bin/elastalert*
	/usr/local/python/bin/elastalert
	/usr/local/python/bin/elastalert-create-index
	/usr/local/python/bin/elastalert-rule-from-kibana
	/usr/local/python/bin/elastalert-test-rule
</code></pre>
<p>软连接到/usr/bin下,方便使用<br>
<code>ln -s /usr/local/python/bin/elastalert* /usr/bin</code></p>
<ul>
<li>elastalert 报警执行的命令,会根据报警规则执行相应操作。</li>
<li>elastalert-create-index会创建一个索引，ElastAlert会把执行记录存放到这个索引中，默认情况下，索引名叫elastalert_status。其中有4个_type，都有自己的@timestamp字段，所以同样也可以用kibana来查看这个索引的日志记录情况。</li>
<li>elastalert-rule-from-kibana从Kibana3已保存的仪表盘中读取Filtering设置，帮助生成config.yaml里的配置。不过注意，它只会读取filtering，不包括queries。</li>
<li>elastalert-test-rule测试自定义配置中的rule设置。</li>
</ul>
<h1 id="使用">使用</h1>
<p>官方文档：https://elastalert.readthedocs.io</p>
<p>规则文档：https://elastalert.readthedocs.io/en/latest/ruletypes.html</p>
<h2 id="主配置文件">主配置文件</h2>
<p>首先是主配置文件的模板为config.yaml.example,生成全局配置</p>
<pre><code>cp config.yaml.example  config.yaml
vim config.yaml
</code></pre>
<pre><code># 用来加载rule的目录，默认是example_rules
rules_folder: rules
# 用来设置定时向elasticsearch发送请求，也就是告警执行的频率
run_every:
  seconds: 30
# 用来设置请求里时间字段的范围
buffer_time:
  seconds: 30
# elasticsearch的host地址,端口
es_host: node01
es_port: 9200
es_username: elastic  elasticsearch认证用户
es_password: d27DuDQjTChIdv3sE8oI
# elastalert产生的日志在elasticsearch中的创建的索引
writeback_index: elastalert_status
writeback_alias: elastalert_alerts
# 失败重试的时间限制
alert_time_limit:
  days: 2
</code></pre>
<h2 id="创建告警索引">创建告警索引</h2>
<p>执行elastalert-create-index命令在ES创建索引，这不是必须的步骤，但是强烈建议创建。因为对于审计和测试很有用，并且重启ES不影响计数和发送alert</p>
<pre><code>[root@test-1 elastalert]# elastalert-create-index
Elastic Version: 7.7.0
Reading Elastic 6 index mappings:
Reading index mapping 'es_mappings/6/silence.json'
Reading index mapping 'es_mappings/6/elastalert_status.json'
Reading index mapping 'es_mappings/6/elastalert.json'
Reading index mapping 'es_mappings/6/past_elastalert.json'
Reading index mapping 'es_mappings/6/elastalert_error.json'
New index elastalert_status created
Done!
</code></pre>
<p>看到这个输出，就说明创建成功了，也可以请求一下看看：</p>
<pre><code>[root@test-1 elastalert]# curl -u elastic 127.0.0.1:9200/_cat/indices?v
Enter host password for user 'elastic':
health status index                     uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   elastalert_status_status  x-ewAZWNR0-vKhvO1gMCnA   1   1          0            0       416b           208b
green  open   elastalert_status         wsOzkDHnT-G0TOzMowBuDQ   1   1          0            0       416b           208b
green  open   .apm-agent-configuration  adCDI2foQaybW_GKiexeFg   1   1          0            0       416b           208b
green  open   elastalert_status_past    1f6xlhtEQvqZSj6Tmyi0pw   1   1          0            0       416b           208b
green  open   elastalert_status_silence Rxi1GdubRdq94cgNShsm_A   1   1          0            0       416b           208b
green  open   .kibana_2                 pXVkkt3aS6CxT0k83AM8Ag   1   1         69           16    254.5kb        127.2kb
green  open   ca-db-2020.06.11          Mh7Yk1XcQb2T7ACTBzKHbQ   1   1         59            0     59.3kb         34.9kb
green  open   .kibana_1                 lCyb8DQqRZ2PxexfMxAmTQ   1   1          1            0     13.7kb          6.8kb
green  open   tomcat-2020.06.10         0M34ANeqSxerM-BYj0-O_A   1   1          3            0     35.6kb         17.8kb
green  open   gateway-2020.06.10        fKGjgXg-QiCsCRHT6XxuRw   1   1       1443            0    808.8kb        404.4kb
green  open   .tasks                    XDOZG-L5TNOeHHCR7hcd4w   1   1          1            0     12.8kb          6.4kb
green  open   .security-7               aPEpVA4eSXSZYWowWT_LZw   1   1         43            1    158.7kb         79.3kb
green  open   ca-server-2020.06.11      Ue3C6cSvR4-6LoUdEiLI4A   1   1         26            0     48.3kb         27.3kb
green  open   .apm-custom-link          rvjLGExARVattrRQnFSH2A   1   1          0            0       416b           208b
green  open   .kibana_task_manager_1    amwNW3LbT2eat9fZTAPdyw   1   1          5           15    102.7kb         56.3kb
green  open   peer_test-2020.06.10      9ig45KJcQwy2y4YYFwVKGA   1   1       1285            0    920.7kb        460.3kb
green  open   .async-search             AcrUB2uUSGueXXr_ueHHzw   1   1          1            1     19.1kb          9.5kb
green  open   elastalert_status_error   wtpRUid1S5CA3Oa6_wAOpg   1   1          0            0       416b           208b
</code></pre>
<h2 id="rule配置">Rule配置</h2>
<p>所有的告警规则，通过在rule目下创建配置文件进行定义，这里简单创建一个来作为演示。</p>
<p>首先我已经在elk集群中配置了一个NGINX日志采集的流水线，现在去kibana中利用检索规则，过滤出我想要的告警内容，比如我想让状态码是404的请求，触发告警通知，就用如下语句进行查询：</p>
<p><code>response: 404</code></p>
<p>其中group是kafka里边定义的组，后边是状态码，还可以写更多条件进行匹配。</p>
<p>然后来到服务器添加一条规则：</p>
<p><code>vim nginx_404.yaml</code></p>
<pre><code class="language-yaml">name: Nginx_err
use_strftine_index: true
index: nginx_info*
type: any
aggregation:
 seconds: 10
filter:
- query:
    query_string:
      query: &quot;response: 404&quot;
alert:
- &quot;email&quot;
email:
 - &quot;test@qq.com&quot;
smtp_host: smtp.163.com
smtp_port: 25
smtp_auth_file: /opt/elastalert/smtp_auth_file.yaml
from_addr: test01@163.com
email_reply_to: teast02@163.com
</code></pre>
<p>注意里边在配置邮件通知的时候，还需要引用外部的一个文件，这个文件里用于存放对应邮箱的用户名密码。</p>
<p><code>vim /opt/elastalert/smtp_auth_file.yaml</code></p>
<pre><code>15726632807@163.com
ZSMIKAVFCLTASBHXV
</code></pre>
<h2 id="规则测试">规则测试</h2>
<p>刚刚已经添加了一条规则，现在可以用自身的命令测试一下刚刚添加的规则。<br>
elastalert-test-rule --config config.yaml nginx_404.yaml</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[关于Logstash中grok插件的正则表达式例子]]></title>
        <id>https://chriswsq.github.io/post/guan-yu-logstash-zhong-grok-cha-jian-de-zheng-ze-biao-da-shi-li-zi/</id>
        <link href="https://chriswsq.github.io/post/guan-yu-logstash-zhong-grok-cha-jian-de-zheng-ze-biao-da-shi-li-zi/">
        </link>
        <updated>2020-08-27T05:51:06.000Z</updated>
        <summary type="html"><![CDATA[<p>日志收集里最重要的就是logstash对日志的过滤，Logstash里提供了一系列的filter来让我们转换日志。Grok就是这些filters里最重要的一个插件，下面就了解下</p>
]]></summary>
        <content type="html"><![CDATA[<p>日志收集里最重要的就是logstash对日志的过滤，Logstash里提供了一系列的filter来让我们转换日志。Grok就是这些filters里最重要的一个插件，下面就了解下</p>
<!-- more -->
<h2 id="grok提供的常用patterns说明及举例">Grok提供的常用Patterns说明及举例</h2>
<p>大多数Linux使用人员都有过用正则表达式来查询机器中相关文件或文件里内容的经历，在Grok里，我们也是使用正则表达式来识别日志里的相关数据块。</p>
<p>有两种方式来使用正则表达式：</p>
<p>直接写正则来匹配<br>
用Grok表达式映射正则来匹配</p>
<h3 id="常用表达式">常用表达式</h3>
<ul>
<li>
<p>GREEDYDATA<br>
<strong>匹配任意字符</strong></p>
</li>
<li>
<p>USERNAME 或 USER<br>
<strong>用户名</strong>，由数字、大小写及特殊字符(._-)组成的字符串</p>
</li>
</ul>
<blockquote>
<p>比如：1234、Bob、Alex.Wong等</p>
</blockquote>
<ul>
<li>EMAILLOCALPART<br>
<strong>电子邮件用户名部分</strong>，首位由大小写字母组成，其他位由数字、大小写及特殊字符(_.+-=:)组成的字符串。注意，国内的QQ纯数字邮箱账号是无法匹配的，需要修改正则</li>
</ul>
<blockquote>
<p>比如：stone、Gary_Lu、abc-123等</p>
</blockquote>
<ul>
<li>EMAILADDRESS<br>
<strong>电子邮件</strong></li>
</ul>
<blockquote>
<p>比如：wwwwaf@abc.com、Gadf_adf@gmail.com、abc-123@163.com等</p>
</blockquote>
<ul>
<li>
<p>HTTPDUSER<br>
Apache服务器的用户，可以是EMAILADDRESS或USERNAME</p>
</li>
<li>
<p>INT<br>
<strong>整数，包括0和正负整数</strong></p>
</li>
</ul>
<blockquote>
<p>比如：0、-123、43987等</p>
</blockquote>
<ul>
<li>BASE10NUM 或 NUMBER<br>
<strong>十进制数字，包括整数和小数</strong></li>
</ul>
<blockquote>
<p>比如：0、18、5.23等</p>
</blockquote>
<ul>
<li>BASE16NUM<br>
<strong>十六进制数字，整数</strong></li>
</ul>
<blockquote>
<p>比如：0x0045fa2d、-0x3F8709等</p>
</blockquote>
<ul>
<li>WORD<br>
<strong>字符串，包括数字和大小写字母</strong></li>
</ul>
<blockquote>
<p>比如：String、3529345、ILoveYou等</p>
</blockquote>
<ul>
<li>
<p>NOTSPACE<br>
<strong>不带任何空格的字符串</strong></p>
</li>
<li>
<p>SPACE<br>
<strong>空格字符串</strong></p>
</li>
<li>
<p>{SPACE}*<br>
**匹配任意连续空格</p>
</li>
<li>
<p>QUOTEDSTRING 或 QS<br>
带引号的字符串</p>
</li>
</ul>
<blockquote>
<p>比如：&quot;This is an apple&quot;、'What is your name?'等</p>
</blockquote>
<ul>
<li>UUID<br>
<strong>标准UUID</strong></li>
</ul>
<blockquote>
<p>比如：550E8400-E29B-11D4-A716-446655440000</p>
</blockquote>
<ul>
<li>
<p>MAC<br>
<strong>MAC地址</strong>，可以是Cisco设备里的MAC地址，也可以是通用或者Windows系统的MAC地址</p>
</li>
<li>
<p>IP<br>
<strong>IP地址</strong>，IPv4或IPv6地址</p>
</li>
</ul>
<blockquote>
<p>比如：127.0.0.1、FE80:0000:0000:0000:AAAA:0000:00C2:0002等</p>
</blockquote>
<ul>
<li>
<p>HOSTNAME<br>
<strong>主机名称</strong></p>
</li>
<li>
<p>IPORHOST<br>
<strong>IP或者主机名称</strong></p>
</li>
<li>
<p>HOSTPORT<br>
<strong>主机名(IP)+端口</strong></p>
</li>
</ul>
<blockquote>
<p>比如：127.0.0.1:3306、api.stozen.net:8000等</p>
</blockquote>
<ul>
<li>PATH<br>
<strong>路径</strong>，Unix系统或者Windows系统里的路径格式</li>
</ul>
<blockquote>
<p>比如：/usr/local/nginx/sbin/nginx、c:\windows\system32\clr.exe等</p>
</blockquote>
<ul>
<li>URIPROTO<br>
<strong>URI协议</strong></li>
</ul>
<blockquote>
<p>比如：http、ftp等</p>
</blockquote>
<ul>
<li>URIHOST<br>
<strong>URI主机</strong></li>
</ul>
<blockquote>
<p>比如：www.baidu.net、10.0.0.1:22等</p>
</blockquote>
<ul>
<li>URIPATH<br>
<strong>URI路径</strong></li>
</ul>
<blockquote>
<p>比如：<code>//www.baidu.net/abc/、/api.php</code>等</p>
</blockquote>
<ul>
<li>URIPARAM<br>
<strong>URI里的GET参数</strong></li>
</ul>
<blockquote>
<p>比如：?a=1&amp;b=2&amp;c=3</p>
</blockquote>
<ul>
<li>URIPATHPARAM<br>
<strong>URI路径+GET参数</strong></li>
</ul>
<blockquote>
<p>比如：<code>//www.google.net/abc/api.php?a=1&amp;b=2&amp;c=3</code></p>
</blockquote>
<ul>
<li>URI<br>
<strong>完整的URI</strong></li>
</ul>
<blockquote>
<p>比如：<code>http://www.google.net/abc/api.php?a=1&amp;b=2&amp;c=3</code></p>
</blockquote>
<h3 id="日期时间表达式">日期时间表达式</h3>
<ul>
<li>MONTH<br>
<strong>月份名称</strong></li>
</ul>
<blockquote>
<p>比如：Jan、January等</p>
</blockquote>
<ul>
<li>MONTHNUM<br>
<strong>月份数字</strong></li>
</ul>
<blockquote>
<p>比如：03、9、12等</p>
</blockquote>
<ul>
<li>MONTHDAY<br>
<strong>日期数字</strong></li>
</ul>
<blockquote>
<p>比如：03、9、31等</p>
</blockquote>
<ul>
<li>DAY<br>
<strong>星期几名称</strong></li>
</ul>
<blockquote>
<p>比如：Mon、Monday等</p>
</blockquote>
<ul>
<li>YEAR<br>
<strong>年份数字</strong></li>
<li>HOUR<br>
<strong>小时数字</strong></li>
<li>MINUTE<br>
<strong>分钟数字</strong></li>
<li>SECOND<br>
<strong>秒数字</strong></li>
<li>TIME<br>
<strong>时间</strong></li>
</ul>
<blockquote>
<p>比如：00:01:23</p>
</blockquote>
<ul>
<li>DATE_US<br>
<strong>美国日期格式</strong></li>
</ul>
<blockquote>
<p>比如：10-15-1982、10/15/1982等</p>
</blockquote>
<ul>
<li>DATE_EU<br>
<strong>欧洲日期格式</strong></li>
</ul>
<blockquote>
<p>比如：15-10-1982、15/10/1982、15.10.1982等</p>
</blockquote>
<ul>
<li>ISO8601_TIMEZONE<br>
<strong>ISO8601时间格式</strong></li>
</ul>
<blockquote>
<p>比如：+10:23、-1023等</p>
</blockquote>
<ul>
<li>TIMESTAMP_ISO8601<br>
<strong>ISO8601时间戳格式</strong></li>
</ul>
<blockquote>
<p>比如：2016-07-03T00:34:06+08:00</p>
</blockquote>
<ul>
<li>
<p>DATE<br>
<strong>日期</strong>，美国日期%{DATE_US}或者欧洲日期%{DATE_EU}</p>
</li>
<li>
<p>DATESTAMP<br>
<strong>完整日期+时间</strong></p>
</li>
</ul>
<blockquote>
<p>比如：07-03-2016 00:34:06</p>
</blockquote>
<ul>
<li>HTTPDATE<br>
<strong>http默认日期格式</strong></li>
</ul>
<blockquote>
<p>比如：03/Jul/2016:00:36:53 +0800</p>
</blockquote>
<h3 id="log表达式">Log表达式</h3>
<ul>
<li>LOGLEVEL<br>
<strong>日志等级</strong></li>
</ul>
<blockquote>
<p>比如：Alert、alert、ALERT、Error等</p>
</blockquote>
<h2 id="创建自己的grok表达式">创建自己的Grok表达式</h2>
<p>在业务领域中，可能会有越来越多的日志格式出现在我们眼前，而Grok的默认表达式显然已无法满足我们的需求（比如用户身份证号、手机号等信息），所以，我们需要自己动手添加些表达式。</p>
<table>
<thead>
<tr>
<th>表达式</th>
<th>正则表达式</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>DATE_CHS</td>
<td>%{YEAR}[./-]%{MONTHNUM}[./-]%{MONTHDAY}</td>
<td>中国人习惯的日期格式</td>
</tr>
<tr>
<td>ZIPCODE_CHS</td>
<td>[1-9]\d{5}</td>
<td>国内邮政编码</td>
</tr>
<tr>
<td>GAME_ACCOUNT</td>
<td>[a-zA-Z][a-zA-Z0-9_]{4,15}</td>
<td>游戏账号，首字符为字母，4-15位字母、数字、下划线组成</td>
</tr>
</tbody>
</table>
<h2 id="其他">其他</h2>
<p>grok正则表达式：(?<temMsg>(.<em>)(?=Report)/?) 获取Report之前的字符<br>
grok正则表达式：(?<temMsg>(?=Report)(.</em>)/?) 获取Report之后的字符</p>
<p><a href="https://www.cnblogs.com/stozen/p/5638369.html">参考</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[生产环境部署fabric]]></title>
        <id>https://chriswsq.github.io/post/sheng-chan-huan-jing-bu-shu-fabric/</id>
        <link href="https://chriswsq.github.io/post/sheng-chan-huan-jing-bu-shu-fabric/">
        </link>
        <updated>2020-08-27T05:40:46.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<h3 id="环境准备">环境准备</h3>
<ul>
<li>
<p>ansible临时添加主机信息</p>
</li>
<li>
<p>修改服务器密码</p>
</li>
<li>
<p>docker</p>
</li>
<li>
<p>docker-compose</p>
</li>
<li>
<p>挂载数据盘</p>
</li>
<li>
<p>传送镜像文件</p>
</li>
</ul>
<h4 id="ansible临时添加主机信息">ansible临时添加主机信息</h4>
<p>因为后续需要根据不同节点传递不同的镜像文件，所以先临时添加节点信息。</p>
<p>例如：龙岩节点   fz</p>
<pre><code class="language-bash">[fz]
z1      ansible_host=121.204.20.15
z2      ansible_host=121.204.220.15
z3      ansible_host=121.204.20.14
z4      ansible_host=121.204.20.15
z5      ansible_host=121.204.20.11
z6      ansible_host=121.204.20.1
z7      ansible_host=121.204.22.14
z8      ansible_host=121.204.20.14
z9      ansible_host=121.204.20.14
z10     ansible_host=121.204.220.1
                     
[fz:vars]
ansible_ssh_port=650
ansible_ssh_pass='123456'
</code></pre>
<h4 id="修改服务器密码">修改服务器密码</h4>
<p>/application/ansible-playbook/optimization/</p>
<pre><code class="language-bash">#推送ansible服务器秘钥
ansible-playbook -e host=fz  push-ssh.yaml
#更改服务器密码
ansible-playbook -e host=fz  changepw.yaml

</code></pre>
<h4 id="安装docker">安装docker</h4>
<p>playbook 地址：<br>
/application/ansible-playbook/optimization</p>
<p><code>ansible-playbook -e host=fz install-docker.yaml</code></p>
<p><strong>安装docker</strong></p>
<pre><code class="language-bash">#安装依赖
ansible     fz  -m shell -a    &quot;yum install -y yum-utils ;yum-config-manager --add-repo   https://download.docker.com/linux/centos/docker-ce.repo&quot;

#从ansible主机传送 docker-ce-18.03.1.ce-1.el7.centos.x86_64.rpm 文件

ansible fz  -m copy -a &quot;src=/home/ansible-playbook/optimization/common/docker-ce-18.03.1.ce-1.el7.centos.x86_64.rpm dest=/root/&quot;

# 安装
ansible fz  -m  shell  -a &quot;yum  -y install docker-ce-18.03.1.ce-1.el7.centos.x86_64.rpm&quot;
</code></pre>
<p><strong>拷贝daemon.json文件</strong></p>
<pre><code class="language-bash">
ansible fz  -m shell -a &quot;mkdir /etc/docker&quot;

ansible fz  -m copy -a &quot;src=/application/ansible-playbook/localnode/fabirc/peer/install-peer/template/daemon.json dest=/etc/docker/&quot;
</code></pre>
<h4 id="安装docker-compose">安装docker-compose</h4>
<p>可在传送镜像是安装也可执行下面命令安装</p>
<pre><code class="language-bash">curl -L https://get.daocloud.io/docker/compose/releases/download/1.12.0/docker-compose-`uname -s`-`uname -m` &gt; ./docker-compose
mv ./docker-compose /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
docker-compose -v
或
ansible fz  -m copy -a &quot;src=/application/ansible-playbook/common/iso/docker-compose dest=/usr/bin/docker-compose mode=0755&quot;
</code></pre>
<blockquote>
<p>注： 如果是手动安装docker 需要调整docker的数据目录<br>
/usr/lib/systemd/system/docker.service</p>
</blockquote>
<h4 id="挂载数据盘">挂载数据盘</h4>
<pre><code class="language-bash">#查看数据盘
fdisk -l
#磁盘分区
fdisk /dev/vdb
n
p
回车
回车
回车
w
#格式化磁盘
mkfs.xfs -n ftype=1 /dev/vdb1
#添加永久挂载
echo '/dev/vdb1                                 /bsn                    xfs     defaults        0 0' &gt;&gt;/etc/fstab
#创建挂在目录
mkdir /bsn
#初始化挂载
mount -a
#查看挂在情况
df -hT

</code></pre>
<h4 id="传送镜像文件">传送镜像文件</h4>
<p>根据节点不同的服务类型来传送不同的镜像</p>
<p><strong>传送服务节点的镜像</strong></p>
<p>使用ansible服务器上  /application/ansible-playbook/optimization/copy.yaml 文件进行传送</p>
<pre><code class="language-bash">- hosts: &quot;{{ host }}&quot;
  remote_user: root
  tasks:
    #- name: 安装zip
    #  yum: name=unzip state=latest
    - name: 创建镜像目录/bsn/iso
      file:
        path: /bsn/iso
        state: directory
        mode: '0755'
    - name: 传镜像
      copy:
        src: /application/ansible-playbook/common/iso/{{ item }}
        dest: /bsn/iso
      with_items:
       # - bsnCa-tomcat9.zip
       # - zipkin.zip
        - docker-compose
        - fabric-peer1.4.3.1.zip
        - fabric-tools1.4.3.1.zip
        - fabric-couchdb.zip
        - fabric-ccenv.zip
        - docker-ce-18.03.1.ce-1.el7.centos.x86_64.rpm
        - fabric-ca-postgresql.zip
        - fabric-ca-service.zip
        - webase-mysql.zip     
        - fabric-gateway.zip   
        - fisco-gm-0.3.zip    
        - webase-mysql.zip
        - webasechainmanager.zip
        - webasesign.zip       
        - gateway-service-v4.zip               
        - zipkin.zip
        - mcs.zip
    - name: 解压
      shell: cd /bsn/iso &amp;&amp; unzip \*.zip
      ignore_errors: yes
</code></pre>
<pre><code class="language-bash">#根据节点所需镜像进行传送，可先将不需要的注释掉

peer节点
        - fabric-peer1.4.3.1.zip
        - fabric-tools1.4.3.1.zip
        - fabric-couchdb.zip
        - fabric-ccenv.zip
        
ca节点		
        - fabric-ca-postgresql.zip
        - fabric-ca-service.zip
        - webase-mysql.zip 
        
网关节点		
        - fabric-gateway.zip  
        - rabbitmq.zip
        - consul.zip
        
fisco节点		
        - fisco-gm-0.3.zip
        
fisco签名服务 链管理
        - webase-mysql.zip
        - webasechainmanager.zip
        - webasesign.zip
        
微服务节点		
        - zipkin.zip
        - mcs.zip
 
</code></pre>
<p><strong>peer节点 （z1  z2  z3）</strong></p>
<pre><code class="language-bash">ansible-playbook -e host=fz copy.yaml -l z1,z2,z3   #保留copy.yaml文件中四个文件，其他注释
</code></pre>
<p><strong>ca节点（z6）</strong></p>
<pre><code class="language-bash">ansible-playbook -e host=fz copy.yaml -l z6   #保留copy.yaml文件中三个文件，其他注释
</code></pre>
<p><strong>网关节点（z4）</strong></p>
<pre><code class="language-bash">ansible-playbook -e host=fz copy.yaml -l z4   #保留copy.yaml文件中三个文件，其他注释
</code></pre>
<blockquote>
<p>注： 因镜像文件较大，传送时间较长，需耐心等候</p>
<p>传送镜像服务结束之后将临时创建的变量文件移除掉（一般移除至/mnt 下）</p>
</blockquote>
<h3 id="部署peer服务">部署peer服务</h3>
<h4 id="修改peer变量文件">修改peer变量文件</h4>
<p>/etc/ansible/inventory/peer1   peer2   peer3</p>
<p>两个方面调整，添加主机组、主机组添加至子组（例如：peer1）</p>
<pre><code class="language-bash">#添加主机组
[fuzhou_peer1]
fuzhou_peer1 ansible_host=121.204.220.16 ansible_ssh_port=22

[fuzhou_peer1:vars]
peer=peer1
name=fuzhou
MSP=Fuzhou
node1=172.31.0.3
node2=172.31.0.1
node3=172.31.0.2
cjq=172.31.0.2

#添加子组
[peer1:children]
suzhou_peer1


</code></pre>
<h4 id="上传peer相关文件">上传peer相关文件</h4>
<p>fuzhou-peer1.zip  fuzhou-peer2.zip  fuzhou-peer3.zip</p>
<p>上传至<br>
/application/ansible-playbook/localnode/fabirc/peer/install-peer/peer-package</p>
<h4 id="部署peer1-2-3">部署peer1 2 3</h4>
<p>执行目录：/application/ansible-playbook/localnode/fabirc/peer/install-peer</p>
<pre><code class="language-bash">ansible-playbook -e host=peer1 install-peer1.yaml -l fuzhou_peer1
ansible-playbook -e host=peer2 install-peer2.yaml -l fuzhou_peer2
ansible-playbook -e host=peer3 install-peer3.yaml -l fuzhou_peer3
</code></pre>
<blockquote>
<p>查看链码这块会报错，忽略即可</p>
</blockquote>
<h3 id="部署ca服务">部署ca服务</h3>
<h4 id="修改ca变量文件">修改ca变量文件</h4>
<p>/etc/ansible/inventory/ca</p>
<p>两个方面调整，添加主机组、主机组添加至子组</p>
<pre><code class="language-bash">#添加群组
[fuzhou_ca]
fuzhou_ca ansible_host=121.204.220.14  ansible_ssh_port=22 name=fuzhou

#添加子组
[ca:children]
fuzhou_ca

</code></pre>
<blockquote>
<p>加入链码部分会报错，待采集器部署完后之后手动加入链码并安装（命令可见playbook文件底部）</p>
</blockquote>
<h4 id="上传ca相关文件">上传ca相关文件</h4>
<p>fuzhou-ca.zip</p>
<p>上传至<br>
/application/ansible-playbook/localnode/fabirc/ca/install-ca/ca-package</p>
<h4 id="部署ca-mysql">部署ca-mysql</h4>
<p>执行目录 /application/ansible-playbook/localnode/fabirc/ca/install-mysql</p>
<pre><code class="language-bash">ansible-playbook -e host=ca install-mysql.yaml -l fuzhou_ca
</code></pre>
<h4 id="部署ca-service">部署ca-service</h4>
<p>执行目录 ：/application/ansible-playbook/localnode/fabirc/ca/install-ca</p>
<pre><code class="language-bash">ansible-playbook -e host=ca install-ca.yaml -l fuzhou_ca
</code></pre>
<h4 id="检查状态">检查状态</h4>
<p>查看数据库表状态</p>
<pre><code class="language-bash">  docker exec cjq-gate-mysql  mysql -uroot -pRed80@80 -e &quot;use bsnflowdb;select * from tb_nc_config&quot;
</code></pre>
<h3 id="部署gateway服务">部署gateway服务</h3>
<h4 id="修改ca变量文件-2">修改ca变量文件</h4>
<p>/etc/ansible/inventory/gateway_M</p>
<p>两个方面调整，添加主机组、主机组添加至子组</p>
<pre><code class="language-bash">#添加主机组
[fuzhou_gateway_M]
fuzhou_gateway_M ansible_host=121.204.220.10  ansible_ssh_port=22

[fuzhou_gateway_M:vars]
name=fuzhou
MSP=Fuzhou
titleName=福州
code=ORG20200804                   #根据当天日志填写即可
node1=172.31.0.31                  #三个peer节点的内网地址
node2=172.31.0.23
node3=172.31.0.26
sign=1.1.1.1                        #没有fisco 填写1.1.1.1
ca=172.31.0.24                      
mcs=1.1.1.1                         #没有微服务 填写1.1.1.1

#添加子组
[gateway_M:children]
nanping_gateway_M

</code></pre>
<h4 id="上传gateway相关文件">上传gateway相关文件</h4>
<p>fuzhou-certs.zip</p>
<p>上传至<br>
/application/ansible-playbook/localnode/fabirc/gateway/install-gate/gateway-certs</p>
<h4 id="部署gateway">部署gateway</h4>
<p>执行目录：/application/ansible-playbook/localnode/fabirc/gateway/install-gate</p>
<pre><code class="language-bash">ansible-playbook -e host=gateway_M install-gate.yaml -l fuzhou_gateway_M
</code></pre>
<h3 id="部署采集器服务">部署采集器服务</h3>
<h4 id="修改cjq变量文件">修改cjq变量文件</h4>
<pre><code class="language-bash">[fuzhou_cjq]
fuzhou_cjq ansible_host=121.204.220.18 ansible_ssh_port=22

[fuzhou_cjq:vars]
name=fuzhou
MSP=Fuzhou
titleName=福州
code=ORG20200804
node1=172.31.0.31
node2=172.31.0.23
node3=172.31.0.26
ca=172.31.0.24
peerport=22
fiscocron=false          #没有fisco则填写false
fiscosign=1.1.1.1        #没有fisco则填写 1.1.1.1
xupercron=false          #没有xupercron则填写false    
mcs=1.1.1.1              #没有微服务则填写1.1.1.1
gmfabriccron=false       #没有微服务则填写false
</code></pre>
<h4 id="上传采集器相关文件">上传采集器相关文件</h4>
<p>fuzhou-collect.zip</p>
<p>上传至<br>
/application/ansible-playbook/localnode/fabirc/cjq/install-cjq/install-package</p>
<h4 id="部署cjq">部署CJQ</h4>
<p>执行目录：/application/ansible-playbook/localnode/fabirc/cjq/install-cjq</p>
<pre><code class="language-bash">ansible-playbook -e host=cjq install-cjq.yaml -l fuzhou_cjq
</code></pre>
<h4 id="查看服务日志">查看服务日志</h4>
<p>/bsn/go/src/node-collect/logs</p>
<pre><code class="language-bash">tail -100f /bsn/go/src/node-collect/logs/catalina.out
</code></pre>
<p>如果出现以下报错，则需要重新加入链，安装链</p>
<pre><code class="language-bash">2020-08-04 13:57:55.381 ERROR 4179 --- [ost-startStop-1] c.b.n.u.C.BaseConfigUtils$Companion      : /bsn/go/src/node-collect/webapps/nodecollectConf/conf/xuperChainBlockResult.properties (No such file or directory)
2020-08-04 13:57:55.487  INFO 4179 --- [ost-startStop-1] c.b.n.utils.NetUtils$Companion           : 请求地址：http://1.1.1.1:5005/WeBASE-Chain-Manager/chain/all
2020-08-04 14:00:02.770  INFO 4179 --- [ost-startStop-1] c.b.n.utils.NetUtils$Companion           : 处理异常：Connection timed out (Connection timed out),附加信息：fisco获取所有链编号
2020-08-04 14:00:02.794 ERROR 4179 --- [ost-startStop-1] c.b.n.u.C.BaseConfigUtils$Companion      : /bsn/go/src/node-collect/webapps/nodecollectConf/conf/sm2FabricBlockResult.properties (No such file or directory)
2020-08-04 14:00:02.830  INFO 4179 --- [ost-startStop-1] c.b.nodecollector.task.FiscoTimeTask     : fisco fbTimetaskopenorclose==false
2020-08-04 14:00:02.831  INFO 4179 --- [ost-startStop-1] c.b.nodecollector.task.FiscoTimeTask     : fisco channelsUploadTime==1200000
2020-08-04 14:00:02.831  INFO 4179 --- [ost-startStop-1] c.b.nodecollector.task.FiscoTimeTask     : fisco blocksUploadTime==1200000
2020-08-04 14:00:02.831  INFO 4179 --- [ost-startStop-1] c.b.nodecollector.task.FiscoTimeTask     : fisco peerResourceUploadTime==600000
</code></pre>
<p>在peer的3个节点执行</p>
<pre><code class="language-bash">#加入链码
docker exec cli peer channel join -b blocktx/netchannel.block

#安装链码
docker exec cli peer chaincode install blocktx/cc_sys.3.0.pak 

</code></pre>
]]></content>
    </entry>
</feed>